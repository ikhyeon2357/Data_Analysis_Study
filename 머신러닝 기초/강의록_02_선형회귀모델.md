## 선형회귀 모델
1. [개요](#1장-개요)   
2. [파라미터 추정](#2장-파라미터-추정)   
    - [실습](#실습)   
3. [파라미터 추론](#3장-파라미터-추론)   
4. [R^2, 분산분석](#4장-R^2,-분산분석)   

### 1장 개요
- x, y 변수 사이의 관계
    - 확정적 관계 : x변수만으로 y변수를 100% 설명
        - ![수식](https://latex.codecogs.com/gif.latex?Y%20%3D%20f%28x%29)
    - 확률적 관계 : x변수와 오차항이 y를 설명
        - ![수식](https://latex.codecogs.com/gif.latex?Y%20%3D%20f%28x%29%20&plus;%20%5Cvarepsilon)

- 선형회귀모델 : 반응변수(Y)를 예측변수(X)들의 선형결합으로 표현한 모델(x, y 사이의 관계를 **수치로 설명** 및 **미래(y)를 예측**)
- 회귀모델의 종류   
![캡처](https://user-images.githubusercontent.com/43491168/109406634-089a2900-79be-11eb-992e-686440967551.PNG)

- 선형회귀모델 가정 :    
![캡처](https://user-images.githubusercontent.com/43491168/109406817-6aa75e00-79bf-11eb-8e82-7f8109e3e49d.PNG)
    - 확률오차 가정 : 
        - ![수식](https://latex.codecogs.com/gif.latex?%5Cvarepsilon_%7Bi%7D%20%5Csim%20N%28o%2C%20%5Csigma%20%5E%7B2%7D%29%2C%20i%20%3D%201%2C2%2C...%2Cn) 
        - ![수식](https://latex.codecogs.com/gif.latex?Y_%7Bi%7D%20%3D%20%5Cbeta%20_%7B0%7D%20&plus;%20%5Cbeta%20_%7B1%7Dx_%7Bi%7D%20&plus;%20%5Cvarepsilon) : 오차항이 확률분포 이므로 Yi도 확률분포를 가진다(즉, Yi는 확률변수이다.)
<!--이하 필기 대체-->
![필기](https://user-images.githubusercontent.com/43491168/109407365-8dd40c80-79c3-11eb-8037-538d75883c88.png)

### 2장 파라미터 추정
![캡처](https://user-images.githubusercontent.com/43491168/109409119-3d64ab00-79d3-11eb-83b8-f35fec2292ae.PNG)

- 비용함수의 형태
    - Cost function is convex -> globally optimal solution exists(전역 최적해[global minimum] <-> 지역 최적해[local minimum])
    - ![비용함수 캡처 추가](https://user-images.githubusercontent.com/43491168/109411393-2038d800-79e5-11eb-97e6-26cfec47039a.PNG)

- 비용함수 추정 알고리즘(최소제곱법, Least Squared Method)
    - ![추정 과정 정리 캡쳐](https://user-images.githubusercontent.com/43491168/109411182-90465e80-79e3-11eb-8b89-a258f273cde8.PNG)

- 잔차(Residual) 와 확률오차(Random Error)차이
    - 잔차 e(Residual, 정해진 값)는 확률오차 Epsilon(Random Error)이 실제로 구현된 값

#### 실습

```python
# 최소제곱법 활용 단순선형회귀 구현
# x : 집크기 / y : 집가격
x = [1380, 3120, 3520, 1130, 1030, 1720, 3920, 1490, 1860, 3430, 2000, 3660, 2500, 1220, 1390]
y = [76, 216, 238, 69, 50, 119, 282, 81, 132, 228, 145, 251, 170, 71, 29]

# x, y mean
x_mean = sum(x)/len(x)
y_mean = sum(y)/len(y)

# beta 1
beta1_hat = sum(list(map(lambda x1, y1 : (x1 - x_mean)*(y1 - y_mean) , x, y))) / sum(list(map(lambda x1 : (x1 - x_mean)**2 , x)))
# beta 0
beta0_hat = y_mean - beta1_hat*x_mean

# 결과 출력
print("Y = ", round(beta0_hat, 1), " + ", round(beta1_hat, 4), "X")
#Y =  -29.6  +  0.0779 X
```
### 3장 파라미터 추론
- Estimator(추정량) : 샘플(x, y)의 함수
    - Least square estimator에서 **beta_0_hat, beat_1_hat = 추정량**
    - 추정량의 용도 : 알려지지 않은 파라미터 추정(beta_0_hat, beat_1_hat 추정)
- 추정량의 종류
    - 점추정(point estimator), 구간추정(interval estimator)
- 최소제곱법 추정량 성질
    - BLUE(best linear unbiased estimator)
        - ![캡처](https://user-images.githubusercontent.com/43491168/109418744-45d9d780-7a0d-11eb-84b4-a822af545b4e.PNG)
        - unbiased estimator(불편추정량) : 모집단의 기대값과 표본의 기대값에 차이(편의)가 없다.

### 4장 R^2, 분산분석
- 결정계수(Coefficient of Determination : R^2)
    - R^2 = SSR/SST = 1 - SSE/SST(0~1)
    - ![Notes_210228_221205](https://user-images.githubusercontent.com/43491168/109419716-2db88700-7a12-11eb-9aaa-3fbf6a3647b3.jpg)    
    - 해석 :
        - x변수가 y변수의 분산을 얼마나 줄였는가
        - 사용하고 있는 x변수의 품질, x변수의 설명력

- 수정결정계수(Adjusted R^2)
    - ![캡처](https://user-images.githubusercontent.com/43491168/109419701-14afd600-7a12-11eb-9eb1-8449b108bab3.PNG)(※ p : 변수의 개수)     
    - 기존 R^2에서 유의하지 않은 변수가 추가되어도 항상 증가하는 문제가 있음.
    - 설명변수가 서로 다른 회귀모형의 설명력을 비교할 때 사용



