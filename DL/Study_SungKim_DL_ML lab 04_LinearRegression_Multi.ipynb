{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7216854e-f003-4bac-9193-8e923e31fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kih\\Anaconda3\\envs\\tf_py36\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab4ae4b3-5099-4c1c-b688-060877568c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis using mattix\n",
    "\n",
    "#          (w1\n",
    "#(x1,x2,x3) w2  = (x1w1 + x2w2 + x3w3)\n",
    "#           w3)\n",
    "\n",
    "# matrix형태 계산시 한번?에 계산 가능(여러 인스턴스를 하나의 mastrix에 넣어 계산)\n",
    "#[5,3]*[3,1]=[5,1]\n",
    "\n",
    "# n output\n",
    "# [n, 3]*[3,2]=[n,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14804fa5-4a50-43b0-b87a-4f6d00e3f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6200bb4-e967-484a-8233-0e7c8d43d22a",
   "metadata": {},
   "source": [
    "# 개별 인스턴스 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24b335e6-24c0-4d21-a315-a535e66ba715",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5704f18e-3518-4a2f-8ef7-9e9a4a03d7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholders for a tensor that will be always fed.\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1 * w1 + x2 * w2 + x3 * w3 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "978d1767-b006-4f40-bdb9-299653cb7433",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  77437.83 \n",
      "Prediction:\n",
      " [ -99.19784 -109.40472 -112.99919 -123.97137  -79.7757 ]\n",
      "20 Cost:  9.441353 \n",
      "Prediction:\n",
      " [147.72311 187.33174 179.40321 194.44539 146.55028]\n",
      "40 Cost:  9.343039 \n",
      "Prediction:\n",
      " [147.74861 187.31851 179.41298 194.45387 146.53104]\n",
      "60 Cost:  9.245787 \n",
      "Prediction:\n",
      " [147.7717  187.30264 179.41998 194.45941 146.50981]\n",
      "80 Cost:  9.149615 \n",
      "Prediction:\n",
      " [147.79465 187.28685 179.42696 194.4649  146.48871]\n",
      "100 Cost:  9.054449 \n",
      "Prediction:\n",
      " [147.81749 187.27113 179.43388 194.47038 146.46773]\n",
      "120 Cost:  8.960345 \n",
      "Prediction:\n",
      " [147.8402  187.25552 179.4408  194.47581 146.44685]\n",
      "140 Cost:  8.867208 \n",
      "Prediction:\n",
      " [147.86278 187.23999 179.44763 194.48123 146.42607]\n",
      "160 Cost:  8.775106 \n",
      "Prediction:\n",
      " [147.88525 187.22456 179.4545  194.48665 146.40544]\n",
      "180 Cost:  8.683998 \n",
      "Prediction:\n",
      " [147.90758 187.20918 179.46126 194.49199 146.38489]\n",
      "200 Cost:  8.593813 \n",
      "Prediction:\n",
      " [147.92982 187.19392 179.46803 194.49734 146.36446]\n",
      "220 Cost:  8.504641 \n",
      "Prediction:\n",
      " [147.9519  187.17871 179.47473 194.50264 146.34412]\n",
      "240 Cost:  8.416445 \n",
      "Prediction:\n",
      " [147.9739  187.16362 179.48141 194.50793 146.32393]\n",
      "260 Cost:  8.329167 \n",
      "Prediction:\n",
      " [147.99574 187.14857 179.48805 194.5132  146.3038 ]\n",
      "280 Cost:  8.242842 \n",
      "Prediction:\n",
      " [148.0175  187.13364 179.49466 194.51842 146.28381]\n",
      "300 Cost:  8.157446 \n",
      "Prediction:\n",
      " [148.0391  187.11874 179.50122 194.5236  146.2639 ]\n",
      "320 Cost:  8.07295 \n",
      "Prediction:\n",
      " [148.06062 187.10397 179.50775 194.5288  146.24413]\n",
      "340 Cost:  7.989418 \n",
      "Prediction:\n",
      " [148.082   187.08926 179.51424 194.53394 146.22446]\n",
      "360 Cost:  7.9066978 \n",
      "Prediction:\n",
      " [148.10327 187.07463 179.5207  194.53908 146.20486]\n",
      "380 Cost:  7.8249145 \n",
      "Prediction:\n",
      " [148.12444 187.06009 179.52713 194.54416 146.1854 ]\n",
      "400 Cost:  7.7440367 \n",
      "Prediction:\n",
      " [148.14546 187.04562 179.5335  194.54924 146.16603]\n",
      "420 Cost:  7.6639853 \n",
      "Prediction:\n",
      " [148.1664  187.03123 179.53986 194.5543  146.14677]\n",
      "440 Cost:  7.58483 \n",
      "Prediction:\n",
      " [148.1872  187.01692 179.54619 194.55931 146.12761]\n",
      "460 Cost:  7.506485 \n",
      "Prediction:\n",
      " [148.2079  187.00269 179.55247 194.56432 146.10855]\n",
      "480 Cost:  7.4290085 \n",
      "Prediction:\n",
      " [148.22849 186.98853 179.55872 194.56929 146.0896 ]\n",
      "500 Cost:  7.352388 \n",
      "Prediction:\n",
      " [148.24895 186.97446 179.56493 194.57422 146.07074]\n",
      "520 Cost:  7.276576 \n",
      "Prediction:\n",
      " [148.2693  186.96045 179.5711  194.57913 146.05199]\n",
      "540 Cost:  7.2015214 \n",
      "Prediction:\n",
      " [148.28957 186.94652 179.57726 194.58405 146.03333]\n",
      "560 Cost:  7.1273346 \n",
      "Prediction:\n",
      " [148.30971 186.93268 179.58337 194.5889  146.01477]\n",
      "580 Cost:  7.0539536 \n",
      "Prediction:\n",
      " [148.32973 186.9189  179.58945 194.59375 145.99632]\n",
      "600 Cost:  6.98135 \n",
      "Prediction:\n",
      " [148.34964 186.9052  179.59549 194.59857 145.97797]\n",
      "620 Cost:  6.9094863 \n",
      "Prediction:\n",
      " [148.36945 186.89157 179.6015  194.60338 145.95969]\n",
      "640 Cost:  6.8384285 \n",
      "Prediction:\n",
      " [148.38914 186.878   179.60747 194.60815 145.94153]\n",
      "660 Cost:  6.7681503 \n",
      "Prediction:\n",
      " [148.40875 186.86455 179.61343 194.6129  145.92348]\n",
      "680 Cost:  6.6986136 \n",
      "Prediction:\n",
      " [148.42824 186.85114 179.61934 194.6176  145.9055 ]\n",
      "700 Cost:  6.6298127 \n",
      "Prediction:\n",
      " [148.44762 186.8378  179.62523 194.62233 145.88763]\n",
      "720 Cost:  6.5617614 \n",
      "Prediction:\n",
      " [148.46689 186.82454 179.63104 194.62698 145.86984]\n",
      "740 Cost:  6.494443 \n",
      "Prediction:\n",
      " [148.48605 186.81136 179.63689 194.63164 145.85216]\n",
      "760 Cost:  6.427844 \n",
      "Prediction:\n",
      " [148.50513 186.79825 179.64267 194.63629 145.83458]\n",
      "780 Cost:  6.361955 \n",
      "Prediction:\n",
      " [148.5241  186.78519 179.64842 194.6409  145.8171 ]\n",
      "800 Cost:  6.296774 \n",
      "Prediction:\n",
      " [148.54295 186.77222 179.65413 194.64548 145.79968]\n",
      "820 Cost:  6.2322984 \n",
      "Prediction:\n",
      " [148.5617  186.75931 179.65982 194.65005 145.78238]\n",
      "840 Cost:  6.1685166 \n",
      "Prediction:\n",
      " [148.58035 186.74648 179.66547 194.65459 145.76515]\n",
      "860 Cost:  6.105435 \n",
      "Prediction:\n",
      " [148.5989  186.73372 179.6711  194.65909 145.74803]\n",
      "880 Cost:  6.043023 \n",
      "Prediction:\n",
      " [148.61736 186.72102 179.67668 194.66359 145.731  ]\n",
      "900 Cost:  5.981279 \n",
      "Prediction:\n",
      " [148.63571 186.70842 179.68227 194.66808 145.71407]\n",
      "920 Cost:  5.9202156 \n",
      "Prediction:\n",
      " [148.65396 186.69588 179.68782 194.67252 145.69722]\n",
      "940 Cost:  5.8597503 \n",
      "Prediction:\n",
      " [148.6721  186.68335 179.6933  194.67693 145.68044]\n",
      "960 Cost:  5.800004 \n",
      "Prediction:\n",
      " [148.69016 186.67096 179.69878 194.68134 145.66377]\n",
      "980 Cost:  5.740856 \n",
      "Prediction:\n",
      " [148.70811 186.65858 179.70422 194.68573 145.6472 ]\n",
      "1000 Cost:  5.68236 \n",
      "Prediction:\n",
      " [148.72597 186.6463  179.70963 194.6901  145.6307 ]\n",
      "1020 Cost:  5.624497 \n",
      "Prediction:\n",
      " [148.74371 186.6341  179.71501 194.69443 145.61429]\n",
      "1040 Cost:  5.567235 \n",
      "Prediction:\n",
      " [148.76135 186.62192 179.72035 194.69873 145.59795]\n",
      "1060 Cost:  5.5106173 \n",
      "Prediction:\n",
      " [148.77895 186.60986 179.7257  194.70303 145.58174]\n",
      "1080 Cost:  5.454577 \n",
      "Prediction:\n",
      " [148.7964  186.59782 179.73099 194.7073  145.56558]\n",
      "1100 Cost:  5.3991575 \n",
      "Prediction:\n",
      " [148.81378 186.58589 179.73627 194.71158 145.54953]\n",
      "1120 Cost:  5.3443284 \n",
      "Prediction:\n",
      " [148.83105 186.57399 179.7415  194.7158  145.53355]\n",
      "1140 Cost:  5.2901154 \n",
      "Prediction:\n",
      " [148.84824 186.56218 179.7467  194.72    145.51767]\n",
      "1160 Cost:  5.2364535 \n",
      "Prediction:\n",
      " [148.86531 186.55042 179.75188 194.72418 145.50185]\n",
      "1180 Cost:  5.183346 \n",
      "Prediction:\n",
      " [148.88232 186.53871 179.75703 194.72836 145.48613]\n",
      "1200 Cost:  5.13087 \n",
      "Prediction:\n",
      " [148.89922 186.52708 179.76215 194.73251 145.4705 ]\n",
      "1220 Cost:  5.078929 \n",
      "Prediction:\n",
      " [148.91603 186.51552 179.76726 194.73663 145.45496]\n",
      "1240 Cost:  5.027538 \n",
      "Prediction:\n",
      " [148.93275 186.50403 179.77231 194.74075 145.43948]\n",
      "1260 Cost:  4.9767065 \n",
      "Prediction:\n",
      " [148.94936 186.49255 179.77733 194.7448  145.42407]\n",
      "1280 Cost:  4.926421 \n",
      "Prediction:\n",
      " [148.96591 186.4812  179.78235 194.74889 145.40878]\n",
      "1300 Cost:  4.8766603 \n",
      "Prediction:\n",
      " [148.98235 186.46986 179.78732 194.75291 145.39354]\n",
      "1320 Cost:  4.827446 \n",
      "Prediction:\n",
      " [148.99872 186.45862 179.79228 194.75697 145.37842]\n",
      "1340 Cost:  4.778745 \n",
      "Prediction:\n",
      " [149.01498 186.44742 179.79721 194.76097 145.36334]\n",
      "1360 Cost:  4.73061 \n",
      "Prediction:\n",
      " [149.03114 186.43628 179.80211 194.76494 145.34836]\n",
      "1380 Cost:  4.682958 \n",
      "Prediction:\n",
      " [149.04724 186.42522 179.80699 194.76894 145.33347]\n",
      "1400 Cost:  4.63581 \n",
      "Prediction:\n",
      " [149.06325 186.4142  179.81184 194.77287 145.31863]\n",
      "1420 Cost:  4.5892005 \n",
      "Prediction:\n",
      " [149.07915 186.40323 179.81664 194.7768  145.3039 ]\n",
      "1440 Cost:  4.5430694 \n",
      "Prediction:\n",
      " [149.09499 186.39235 179.82146 194.7807  145.28923]\n",
      "1460 Cost:  4.497428 \n",
      "Prediction:\n",
      " [149.11072 186.3815  179.8262  194.78458 145.27463]\n",
      "1480 Cost:  4.452293 \n",
      "Prediction:\n",
      " [149.12639 186.37074 179.83095 194.78845 145.26013]\n",
      "1500 Cost:  4.407655 \n",
      "Prediction:\n",
      " [149.14194 186.36003 179.83566 194.79231 145.2457 ]\n",
      "1520 Cost:  4.363466 \n",
      "Prediction:\n",
      " [149.15742 186.34935 179.84033 194.79613 145.23134]\n",
      "1540 Cost:  4.3197694 \n",
      "Prediction:\n",
      " [149.17284 186.33878 179.84502 194.79996 145.21707]\n",
      "1560 Cost:  4.276538 \n",
      "Prediction:\n",
      " [149.18816 186.32823 179.84966 194.80373 145.20287]\n",
      "1580 Cost:  4.2337756 \n",
      "Prediction:\n",
      " [149.20337 186.31773 179.85425 194.80751 145.18874]\n",
      "1600 Cost:  4.191451 \n",
      "Prediction:\n",
      " [149.21852 186.3073  179.85884 194.81123 145.17467]\n",
      "1620 Cost:  4.149599 \n",
      "Prediction:\n",
      " [149.23358 186.29694 179.86339 194.81499 145.16069]\n",
      "1640 Cost:  4.10819 \n",
      "Prediction:\n",
      " [149.24857 186.28662 179.86795 194.81871 145.14679]\n",
      "1660 Cost:  4.067219 \n",
      "Prediction:\n",
      " [149.26347 186.27635 179.87244 194.82242 145.13297]\n",
      "1680 Cost:  4.0266967 \n",
      "Prediction:\n",
      " [149.27829 186.26616 179.87692 194.8261  145.1192 ]\n",
      "1700 Cost:  3.9866452 \n",
      "Prediction:\n",
      " [149.29301 186.25601 179.88138 194.82974 145.10553]\n",
      "1720 Cost:  3.9469552 \n",
      "Prediction:\n",
      " [149.30768 186.24593 179.88583 194.8334  145.0919 ]\n",
      "1740 Cost:  3.907721 \n",
      "Prediction:\n",
      " [149.32227 186.2359  179.89023 194.83704 145.07837]\n",
      "1760 Cost:  3.868916 \n",
      "Prediction:\n",
      " [149.33675 186.22589 179.8946  194.84062 145.0649 ]\n",
      "1780 Cost:  3.8305397 \n",
      "Prediction:\n",
      " [149.35115 186.21597 179.89897 194.84421 145.0515 ]\n",
      "1800 Cost:  3.7925434 \n",
      "Prediction:\n",
      " [149.36552 186.20612 179.90334 194.8478  145.0382 ]\n",
      "1820 Cost:  3.754975 \n",
      "Prediction:\n",
      " [149.37976 186.19627 179.90762 194.85135 145.02493]\n",
      "1840 Cost:  3.7177856 \n",
      "Prediction:\n",
      " [149.39395 186.18651 179.91191 194.8549  145.01175]\n",
      "1860 Cost:  3.6810403 \n",
      "Prediction:\n",
      " [149.40805 186.1768  179.91618 194.8584  144.99864]\n",
      "1880 Cost:  3.644645 \n",
      "Prediction:\n",
      " [149.42209 186.16714 179.92041 194.86191 144.9856 ]\n",
      "1900 Cost:  3.6086648 \n",
      "Prediction:\n",
      " [149.43604 186.15755 179.92465 194.8654  144.97263]\n",
      "1920 Cost:  3.5730813 \n",
      "Prediction:\n",
      " [149.44989 186.14798 179.92883 194.86885 144.95972]\n",
      "1940 Cost:  3.5378528 \n",
      "Prediction:\n",
      " [149.4637  186.13847 179.93301 194.8723  144.94688]\n",
      "1960 Cost:  3.5030074 \n",
      "Prediction:\n",
      " [149.47742 186.12903 179.93716 194.87575 144.93411]\n",
      "1980 Cost:  3.468542 \n",
      "Prediction:\n",
      " [149.49107 186.11963 179.94128 194.87915 144.92142]\n",
      "2000 Cost:  3.4344382 \n",
      "Prediction:\n",
      " [149.50464 186.11029 179.9454  194.88258 144.90878]\n"
     ]
    }
   ],
   "source": [
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize. Need a very small learning rate for this data set\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "    if step % 20 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a8128d-f766-46d0-9a75-e59d01d27c02",
   "metadata": {},
   "source": [
    "# Matrix 형택 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "042af3dd-5865-46d7-968f-ccde6f1056ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[73., 80., 75.],\n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.],\n",
    "          [96., 98., 100.],\n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.],\n",
    "          [185.],\n",
    "          [180.],\n",
    "          [196.],\n",
    "          [142.]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3]) # None = n개, 3 = 3열\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight') # Weight의 모양 = [3, 1]\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias') # bias의 모양 = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7f87ba-26cc-414e-8ed5-454562554ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82c0175b-e085-42ec-88db-f50a4161e8f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  2861.9668 \n",
      "Prediction:\n",
      " [[105.63413 ]\n",
      " [126.47547 ]\n",
      " [125.023895]\n",
      " [135.61624 ]\n",
      " [ 96.54288 ]]\n",
      "100 Cost:  1.789065 \n",
      "Prediction:\n",
      " [[153.03859]\n",
      " [183.54329]\n",
      " [181.20644]\n",
      " [196.80182]\n",
      " [140.09048]]\n",
      "200 Cost:  1.708155 \n",
      "Prediction:\n",
      " [[152.99164]\n",
      " [183.57559]\n",
      " [181.1922 ]\n",
      " [196.79037]\n",
      " [140.13387]]\n",
      "300 Cost:  1.6314819 \n",
      "Prediction:\n",
      " [[152.94594]\n",
      " [183.60704]\n",
      " [181.17836]\n",
      " [196.77919]\n",
      " [140.1761 ]]\n",
      "400 Cost:  1.558845 \n",
      "Prediction:\n",
      " [[152.9015 ]\n",
      " [183.63765]\n",
      " [181.16487]\n",
      " [196.76831]\n",
      " [140.21722]]\n",
      "500 Cost:  1.4900503 \n",
      "Prediction:\n",
      " [[152.85823]\n",
      " [183.66739]\n",
      " [181.15176]\n",
      " [196.75769]\n",
      " [140.25725]]\n",
      "600 Cost:  1.4248439 \n",
      "Prediction:\n",
      " [[152.81616]\n",
      " [183.69637]\n",
      " [181.139  ]\n",
      " [196.74731]\n",
      " [140.29623]]\n",
      "700 Cost:  1.3630717 \n",
      "Prediction:\n",
      " [[152.7752 ]\n",
      " [183.72455]\n",
      " [181.12659]\n",
      " [196.73718]\n",
      " [140.33417]]\n",
      "800 Cost:  1.3045632 \n",
      "Prediction:\n",
      " [[152.73538]\n",
      " [183.75198]\n",
      " [181.11456]\n",
      " [196.72736]\n",
      " [140.37114]]\n",
      "900 Cost:  1.2491057 \n",
      "Prediction:\n",
      " [[152.69662]\n",
      " [183.77867]\n",
      " [181.10281]\n",
      " [196.71773]\n",
      " [140.40712]]\n",
      "1000 Cost:  1.1965659 \n",
      "Prediction:\n",
      " [[152.6589 ]\n",
      " [183.80463]\n",
      " [181.09138]\n",
      " [196.70834]\n",
      " [140.44215]]\n"
     ]
    }
   ],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(1001):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9d1596-73fd-483a-88fc-08214e42f2e0",
   "metadata": {},
   "source": [
    "# Matrix 형택 학습 - Load Xmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccd52a9d-ca2a-40d6-8639-8f278c58a1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]\n",
      " [ 69.  74.  77.]\n",
      " [ 47.  56.  60.]\n",
      " [ 87.  79.  90.]\n",
      " [ 79.  70.  88.]\n",
      " [ 69.  70.  73.]\n",
      " [ 70.  65.  74.]\n",
      " [ 93.  95.  91.]\n",
      " [ 79.  80.  73.]\n",
      " [ 70.  73.  78.]\n",
      " [ 93.  89.  96.]\n",
      " [ 78.  75.  68.]\n",
      " [ 81.  90.  93.]\n",
      " [ 88.  92.  86.]\n",
      " [ 78.  83.  77.]\n",
      " [ 82.  86.  90.]\n",
      " [ 86.  82.  89.]\n",
      " [ 78.  83.  85.]\n",
      " [ 76.  83.  71.]\n",
      " [ 96.  93.  95.]] \n",
      "x_data shape: (25, 3)\n",
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]\n",
      " [149.]\n",
      " [115.]\n",
      " [175.]\n",
      " [164.]\n",
      " [141.]\n",
      " [141.]\n",
      " [184.]\n",
      " [152.]\n",
      " [148.]\n",
      " [192.]\n",
      " [147.]\n",
      " [183.]\n",
      " [177.]\n",
      " [159.]\n",
      " [177.]\n",
      " [175.]\n",
      " [175.]\n",
      " [149.]\n",
      " [192.]] \n",
      "y_data shape: (25, 1)\n"
     ]
    }
   ],
   "source": [
    "path = 'D:/WorkSpace/Python/강의자료 구현/DeepLearningZeroToAll-master/'\n",
    "xy = np.loadtxt(path+'data-01-test-score.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "print(x_data, \"\\nx_data shape:\", x_data.shape)\n",
    "print(y_data, \"\\ny_data shape:\", y_data.shape)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6af3b0f-fcd8-47d6-8c9e-3677320682bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost: 68479.24 \n",
      "Prediction:\n",
      " [[ -96.46343 ]\n",
      " [-109.81928 ]\n",
      " [-111.79769 ]\n",
      " [-119.038536]\n",
      " [ -84.00308 ]\n",
      " [ -56.08633 ]\n",
      " [ -86.056404]\n",
      " [ -59.935307]\n",
      " [ -97.40455 ]\n",
      " [ -83.02706 ]\n",
      " [ -83.865944]\n",
      " [ -78.64712 ]\n",
      " [-118.44631 ]\n",
      " [-101.81907 ]\n",
      " [ -85.158585]\n",
      " [-109.30164 ]\n",
      " [ -98.36591 ]\n",
      " [-103.39904 ]\n",
      " [-114.2934  ]\n",
      " [-102.214226]\n",
      " [-101.391   ]\n",
      " [-100.46287 ]\n",
      " [ -97.95316 ]\n",
      " [-103.9799  ]\n",
      " [-116.30046 ]]\n",
      "100 Cost: 17.887838 \n",
      "Prediction:\n",
      " [[149.70439]\n",
      " [185.80379]\n",
      " [179.61821]\n",
      " [198.2637 ]\n",
      " [141.45518]\n",
      " [109.99501]\n",
      " [151.41817]\n",
      " [116.06918]\n",
      " [178.73096]\n",
      " [172.56065]\n",
      " [144.92833]\n",
      " [146.81187]\n",
      " [182.69577]\n",
      " [148.60406]\n",
      " [153.36256]\n",
      " [190.64073]\n",
      " [140.13942]\n",
      " [181.60585]\n",
      " [172.85208]\n",
      " [154.72633]\n",
      " [177.07562]\n",
      " [176.81699]\n",
      " [167.58429]\n",
      " [144.37811]\n",
      " [190.15141]]\n",
      "200 Cost: 16.924921 \n",
      "Prediction:\n",
      " [[149.85117 ]\n",
      " [185.74252 ]\n",
      " [179.68599 ]\n",
      " [198.26912 ]\n",
      " [141.40578 ]\n",
      " [109.82514 ]\n",
      " [151.38712 ]\n",
      " [116.004135]\n",
      " [178.53496 ]\n",
      " [172.20662 ]\n",
      " [144.8978  ]\n",
      " [146.65063 ]\n",
      " [182.83162 ]\n",
      " [148.79875 ]\n",
      " [153.28828 ]\n",
      " [190.53534 ]\n",
      " [140.33409 ]\n",
      " [181.58054 ]\n",
      " [173.02907 ]\n",
      " [154.89798 ]\n",
      " [177.02948 ]\n",
      " [176.70795 ]\n",
      " [167.57994 ]\n",
      " [144.68047 ]\n",
      " [190.15749 ]]\n",
      "300 Cost: 16.04392 \n",
      "Prediction:\n",
      " [[149.99161]\n",
      " [185.6839 ]\n",
      " [179.75081]\n",
      " [198.27432]\n",
      " [141.35841]\n",
      " [109.66263]\n",
      " [151.35748]\n",
      " [115.94205]\n",
      " [178.34744]\n",
      " [171.86795]\n",
      " [144.86859]\n",
      " [146.49637]\n",
      " [182.96155]\n",
      " [148.98492]\n",
      " [153.2173 ]\n",
      " [190.43452]\n",
      " [140.5202 ]\n",
      " [181.55646]\n",
      " [173.19836]\n",
      " [155.06216]\n",
      " [176.98541]\n",
      " [176.60364]\n",
      " [167.57584]\n",
      " [144.96967]\n",
      " [190.16322]]\n",
      "400 Cost: 15.237827 \n",
      "Prediction:\n",
      " [[150.12598]\n",
      " [185.62775]\n",
      " [179.81279]\n",
      " [198.27931]\n",
      " [141.31303]\n",
      " [109.50712]\n",
      " [151.32918]\n",
      " [115.88277]\n",
      " [178.168  ]\n",
      " [171.54396]\n",
      " [144.84068]\n",
      " [146.34879]\n",
      " [183.0858 ]\n",
      " [149.16295]\n",
      " [153.14943]\n",
      " [190.33806]\n",
      " [140.69814]\n",
      " [181.53351]\n",
      " [173.36028]\n",
      " [155.21922]\n",
      " [176.94328]\n",
      " [176.50383]\n",
      " [167.57195]\n",
      " [145.24629]\n",
      " [190.16867]]\n",
      "500 Cost: 14.500327 \n",
      "Prediction:\n",
      " [[150.25455 ]\n",
      " [185.574   ]\n",
      " [179.87212 ]\n",
      " [198.2841  ]\n",
      " [141.26956 ]\n",
      " [109.358345]\n",
      " [151.30219 ]\n",
      " [115.82619 ]\n",
      " [177.99634 ]\n",
      " [171.23409 ]\n",
      " [144.814   ]\n",
      " [146.20761 ]\n",
      " [183.20465 ]\n",
      " [149.33319 ]\n",
      " [153.08458 ]\n",
      " [190.24576 ]\n",
      " [140.86824 ]\n",
      " [181.51169 ]\n",
      " [173.51517 ]\n",
      " [155.36948 ]\n",
      " [176.90306 ]\n",
      " [176.40834 ]\n",
      " [167.5683  ]\n",
      " [145.5109  ]\n",
      " [190.17387 ]]\n",
      "600 Cost: 13.825542 \n",
      "Prediction:\n",
      " [[150.37756]\n",
      " [185.52257]\n",
      " [179.92885]\n",
      " [198.28871]\n",
      " [141.22792]\n",
      " [109.21598]\n",
      " [151.27641]\n",
      " [115.77216]\n",
      " [177.8321 ]\n",
      " [170.93764]\n",
      " [144.7885 ]\n",
      " [146.07254]\n",
      " [183.31831]\n",
      " [149.496  ]\n",
      " [153.02258]\n",
      " [190.15747]\n",
      " [141.03085]\n",
      " [181.49089]\n",
      " [173.66331]\n",
      " [155.51318]\n",
      " [176.86464]\n",
      " [176.317  ]\n",
      " [167.56487]\n",
      " [145.76398]\n",
      " [190.17879]]\n",
      "700 Cost: 13.208172 \n",
      "Prediction:\n",
      " [[150.49525]\n",
      " [185.47328]\n",
      " [179.98311]\n",
      " [198.2931 ]\n",
      " [141.18799]\n",
      " [109.07977]\n",
      " [151.25183]\n",
      " [115.72061]\n",
      " [177.67494]\n",
      " [170.65407]\n",
      " [144.76408]\n",
      " [145.94333]\n",
      " [183.42702]\n",
      " [149.65169]\n",
      " [152.96333]\n",
      " [190.07297]\n",
      " [141.18631]\n",
      " [181.4711 ]\n",
      " [173.80501]\n",
      " [155.65065]\n",
      " [176.82793]\n",
      " [176.22957]\n",
      " [167.5616 ]\n",
      " [146.00606]\n",
      " [190.18343]]\n",
      "800 Cost: 12.643259 \n",
      "Prediction:\n",
      " [[150.60788 ]\n",
      " [185.42615 ]\n",
      " [180.03502 ]\n",
      " [198.29736 ]\n",
      " [141.14975 ]\n",
      " [108.94944 ]\n",
      " [151.22836 ]\n",
      " [115.671394]\n",
      " [177.52458 ]\n",
      " [170.38281 ]\n",
      " [144.74077 ]\n",
      " [145.81972 ]\n",
      " [183.53098 ]\n",
      " [149.80057 ]\n",
      " [152.9067  ]\n",
      " [189.99214 ]\n",
      " [141.33495 ]\n",
      " [181.45229 ]\n",
      " [173.94055 ]\n",
      " [155.78218 ]\n",
      " [176.79288 ]\n",
      " [176.14595 ]\n",
      " [167.55856 ]\n",
      " [146.23763 ]\n",
      " [190.18788 ]]\n",
      "900 Cost: 12.126408 \n",
      "Prediction:\n",
      " [[150.71564]\n",
      " [185.381  ]\n",
      " [180.08469]\n",
      " [198.30144]\n",
      " [141.1131 ]\n",
      " [108.82474]\n",
      " [151.20598]\n",
      " [115.62442]\n",
      " [177.3807 ]\n",
      " [170.12332]\n",
      " [144.71848]\n",
      " [145.70145]\n",
      " [183.63042]\n",
      " [149.94293]\n",
      " [152.85257]\n",
      " [189.91481]\n",
      " [141.47704]\n",
      " [181.43437]\n",
      " [174.07019]\n",
      " [155.90797]\n",
      " [176.75938]\n",
      " [176.06593]\n",
      " [167.5557 ]\n",
      " [146.4591 ]\n",
      " [190.19208]]\n",
      "1000 Cost: 11.653518 \n",
      "Prediction:\n",
      " [[150.81874 ]\n",
      " [185.33778 ]\n",
      " [180.13217 ]\n",
      " [198.30534 ]\n",
      " [141.07799 ]\n",
      " [108.705414]\n",
      " [151.1846  ]\n",
      " [115.57958 ]\n",
      " [177.24306 ]\n",
      " [169.8751  ]\n",
      " [144.69717 ]\n",
      " [145.5883  ]\n",
      " [183.72552 ]\n",
      " [150.07906 ]\n",
      " [152.80083 ]\n",
      " [189.8408  ]\n",
      " [141.61285 ]\n",
      " [181.41734 ]\n",
      " [174.1942  ]\n",
      " [156.0283  ]\n",
      " [176.7274  ]\n",
      " [175.98938 ]\n",
      " [167.553   ]\n",
      " [146.67097 ]\n",
      " [190.19606 ]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(1001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], \n",
    "                                   feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"Cost:\", cost_val, \"\\nPrediction:\\n\", hy_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ab923-6fac-4382-aa5e-d13cbcca536b",
   "metadata": {},
   "source": [
    "# Queue Runners\n",
    "\n",
    "### - Queue Runners 참고 : https://blog.naver.com/heartflow89/221086772536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fc721d4-a78b-491e-977d-f89723f7521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'D:/WorkSpace/Python/강의자료 구현/DeepLearningZeroToAll-master/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3560e5cd-f79f-49aa-86b8-a55b4869dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 4 Multi-variable linear regression\n",
    "# https://www.tensorflow.org/programmers_guide/reading_data\n",
    "\n",
    "# tf.train.string_input_producer\n",
    "# filename 목록을 넘겨받음 \n",
    "# ex : tf.train.string_input_producer([\"file0.csv\", \"file1.csv\", ......])\n",
    "# name: A name for the operation (optional).\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    [path + 'data-01-test-score.csv'], shuffle=False, name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader() # 파일의 한줄씩 읽어서 리턴\n",
    "key, value = reader.read(filename_queue)\n",
    "# value : 파일에서 읽은 값\n",
    "# key : (파일 이름인듯)b'D:/WorkSpace/Python/\\xea\\xb0\\x95\\xec\\x9d\\x98\\xec\\x9e\\x90\\xeb\\xa3\\x8c \\xea\\xb5\\xac\\xed\\x98\\x84/DeepLearningZeroToAll-master/data-01-test-score.csv:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "523f9cf9-bde6-425b-b8b9-e5ed7c1123f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Point\n",
    "\n",
    "#sess = tf.Session()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "#coord = tf.train.Coordinator()\n",
    "#threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "#sess.run(key)\n",
    "#sess.run(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be06ca0-a2ea-47d7-8ff0-5c0ee6b29080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-10-cc6f3b349143>:8: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "# Default values, in case of empty columns. Also specifies the type of the\n",
    "# decoded result.\n",
    "record_defaults = [[0.], [0.], [0.], [0.]] # 입력 변수의 type 및 null값 처리\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)\n",
    "\n",
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10) # batch_size : 10등분\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8be76789-7059-499b-b3ae-6cd2290ab286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  2598.893 \n",
      "Prediction:\n",
      " [[105.63413 ]\n",
      " [126.47547 ]\n",
      " [125.023895]\n",
      " [135.61624 ]\n",
      " [ 96.54288 ]\n",
      " [ 69.79834 ]\n",
      " [100.468285]\n",
      " [ 73.146675]\n",
      " [117.17079 ]\n",
      " [106.953476]]\n",
      "100 Cost:  11.245397 \n",
      "Prediction:\n",
      " [[154.6236 ]\n",
      " [185.49474]\n",
      " [183.09875]\n",
      " [198.94257]\n",
      " [141.5244 ]\n",
      " [103.09856]\n",
      " [147.94803]\n",
      " [108.44992]\n",
      " [172.45642]\n",
      " [158.34714]]\n",
      "200 Cost:  10.604915 \n",
      "Prediction:\n",
      " [[154.53923]\n",
      " [185.51482]\n",
      " [183.04994]\n",
      " [198.96269]\n",
      " [141.50941]\n",
      " [103.21482]\n",
      " [148.03806]\n",
      " [108.61786]\n",
      " [172.59294]\n",
      " [158.64653]]\n",
      "300 Cost:  10.022897 \n",
      "Prediction:\n",
      " [[154.45927]\n",
      " [185.53311]\n",
      " [183.00323]\n",
      " [198.98215]\n",
      " [141.49379]\n",
      " [103.32515]\n",
      " [148.12506]\n",
      " [108.78026]\n",
      " [172.72246]\n",
      " [158.9321 ]]\n",
      "400 Cost:  9.493998 \n",
      "Prediction:\n",
      " [[154.38356 ]\n",
      " [185.54974 ]\n",
      " [182.95862 ]\n",
      " [199.00096 ]\n",
      " [141.47762 ]\n",
      " [103.429794]\n",
      " [148.20918 ]\n",
      " [108.93735 ]\n",
      " [172.84534 ]\n",
      " [159.20451 ]]\n",
      "500 Cost:  9.013475 \n",
      "Prediction:\n",
      " [[154.31184]\n",
      " [185.5648 ]\n",
      " [182.916  ]\n",
      " [199.01913]\n",
      " [141.46095]\n",
      " [103.52904]\n",
      " [148.29048]\n",
      " [109.08928]\n",
      " [172.96185]\n",
      " [159.46434]]\n",
      "600 Cost:  8.576848 \n",
      "Prediction:\n",
      " [[154.24396]\n",
      " [185.57838]\n",
      " [182.87523]\n",
      " [199.03673]\n",
      " [141.44382]\n",
      " [103.62315]\n",
      " [148.36913]\n",
      " [109.23629]\n",
      " [173.07234]\n",
      " [159.71217]]\n",
      "700 Cost:  8.180216 \n",
      "Prediction:\n",
      " [[154.17972]\n",
      " [185.59059]\n",
      " [182.83633]\n",
      " [199.05376]\n",
      " [141.42632]\n",
      " [103.71238]\n",
      " [148.44518]\n",
      " [109.37852]\n",
      " [173.17711]\n",
      " [159.94858]]\n",
      "800 Cost:  7.8198996 \n",
      "Prediction:\n",
      " [[154.11893]\n",
      " [185.60147]\n",
      " [182.7991 ]\n",
      " [199.07022]\n",
      " [141.40843]\n",
      " [103.79695]\n",
      " [148.5187 ]\n",
      " [109.51614]\n",
      " [173.27638]\n",
      " [160.17403]]\n",
      "900 Cost:  7.4926424 \n",
      "Prediction:\n",
      " [[154.06143 ]\n",
      " [185.6111  ]\n",
      " [182.76353 ]\n",
      " [199.08617 ]\n",
      " [141.39024 ]\n",
      " [103.87709 ]\n",
      " [148.58984 ]\n",
      " [109.649315]\n",
      " [173.37047 ]\n",
      " [160.38904 ]]\n",
      "1000 Cost:  7.1954026 \n",
      "Prediction:\n",
      " [[154.00706 ]\n",
      " [185.61958 ]\n",
      " [182.72954 ]\n",
      " [199.10158 ]\n",
      " [141.37178 ]\n",
      " [103.95302 ]\n",
      " [148.65866 ]\n",
      " [109.778206]\n",
      " [173.45958 ]\n",
      " [160.5941  ]]\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(1001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n",
    "    if step % 100 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf886c20-b37b-4ade-aef8-c2a9f91e74c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score will be  [[184.1228]]\n",
      "Other scores will be  [[162.44106]\n",
      " [182.35104]]\n"
     ]
    }
   ],
   "source": [
    "# Ask my score\n",
    "print(\"Your score will be \",\n",
    "      sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))\n",
    "\n",
    "print(\"Other scores will be \",\n",
    "      sess.run(hypothesis, feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
