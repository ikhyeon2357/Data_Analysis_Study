{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31bd5c-6ef1-4dde-b120-320eb3366838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow Step\n",
    "# Build graph -> Session Run -> Updata variable and Return Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7216854e-f003-4bac-9193-8e923e31fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa959d1-3557-43b6-b078-5ffc4b637485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X and Y data\n",
    "x_train = [1, 2, 3]\n",
    "y_train = [1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72069be6-899f-4277-b693-4771f0141014",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03afe882-75ec-4653-8fb0-894d69537e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our hypothesis XW+b\n",
    "hypothesis = x_train * W + b\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e1e3a7-8132-4b1e-870d-3475ca580e59",
   "metadata": {},
   "source": [
    "# 그래프 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d542b31-651f-4cf2-ad34-df51f10e59c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88911f8b-ed48-4585-92dc-cad918a38f2f",
   "metadata": {},
   "source": [
    "# Session 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46c3aae1-b03d-478b-8dd2-c5d741fe3965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer()) # tensorflow상에서 W, b변수 initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02d9e7f6-8fb0-40a0-af04-b1e464dd1929",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 36.646107 [-2.1609282] [0.8459881]\n",
      "20 0.78518754 [-0.00806797] [1.6879286]\n",
      "40 0.4184753 [0.2301563] [1.6925567]\n",
      "60 0.37739444 [0.28450865] [1.6210068]\n",
      "80 0.34273136 [0.31986454] [1.5455867]\n",
      "100 0.31127396 [0.35199317] [1.4730222]\n",
      "120 0.28270403 [0.38246274] [1.4038026]\n",
      "140 0.25675634 [0.41148618] [1.3378298]\n",
      "160 0.2331903 [0.4391443] [1.274957]\n",
      "180 0.21178712 [0.4655024] [1.2150387]\n",
      "200 0.19234848 [0.49062183] [1.1579365]\n",
      "220 0.17469405 [0.51456064] [1.1035178]\n",
      "240 0.15865992 [0.5373745] [1.0516565]\n",
      "260 0.14409752 [0.5591161] [1.0022327]\n",
      "280 0.1308717 [0.5798361] [0.9551314]\n",
      "300 0.11885974 [0.59958225] [0.91024375]\n",
      "320 0.10795034 [0.61840034] [0.8674657]\n",
      "340 0.09804226 [0.63633406] [0.8266981]\n",
      "360 0.08904353 [0.6534251] [0.78784627]\n",
      "380 0.0808708 [0.6697127] [0.7508205]\n",
      "400 0.07344813 [0.6852351] [0.7155347]\n",
      "420 0.066706814 [0.7000278] [0.6819073]\n",
      "440 0.060584176 [0.7141254] [0.64986014]\n",
      "460 0.05502352 [0.72756046] [0.6193191]\n",
      "480 0.04997323 [0.74036413] [0.59021336]\n",
      "500 0.045386504 [0.75256604] [0.5624755]\n",
      "520 0.04122074 [0.7641945] [0.5360412]\n",
      "540 0.03743733 [0.7752765] [0.51084924]\n",
      "560 0.034001183 [0.7858377] [0.4868412]\n",
      "580 0.03088043 [0.7959025] [0.4639615]\n",
      "600 0.028046092 [0.80549437] [0.442157]\n",
      "620 0.025471903 [0.8146354] [0.42137724]\n",
      "640 0.023134006 [0.82334685] [0.4015741]\n",
      "660 0.021010661 [0.83164895] [0.3827016]\n",
      "680 0.01908222 [0.8395608] [0.364716]\n",
      "700 0.017330782 [0.8471008] [0.3475757]\n",
      "720 0.015740102 [0.85428655] [0.3312409]\n",
      "740 0.014295399 [0.8611346] [0.3156738]\n",
      "760 0.012983318 [0.8676607] [0.30083826]\n",
      "780 0.011791654 [0.87388015] [0.28669995]\n",
      "800 0.010709369 [0.8798074] [0.2732261]\n",
      "820 0.009726416 [0.885456] [0.26038542]\n",
      "840 0.008833681 [0.89083916] [0.24814826]\n",
      "860 0.008022902 [0.8959693] [0.23648623]\n",
      "880 0.0072865174 [0.9008584] [0.2253722]\n",
      "900 0.006617731 [0.90551764] [0.21478052]\n",
      "920 0.0060103317 [0.90995795] [0.20468669]\n",
      "940 0.0054586832 [0.9141896] [0.19506718]\n",
      "960 0.0049576703 [0.9182223] [0.18589978]\n",
      "980 0.004502636 [0.9220656] [0.1771632]\n",
      "1000 0.004089364 [0.92572826] [0.16883717]\n",
      "1020 0.0037140269 [0.9292187] [0.16090246]\n",
      "1040 0.0033731367 [0.9325452] [0.15334064]\n",
      "1060 0.003063536 [0.93571526] [0.1461342]\n",
      "1080 0.002782352 [0.9387365] [0.13926646]\n",
      "1100 0.002526978 [0.9416156] [0.13272141]\n",
      "1120 0.0022950398 [0.9443594] [0.12648402]\n",
      "1140 0.0020843935 [0.94697434] [0.12053975]\n",
      "1160 0.0018930797 [0.94946647] [0.11487483]\n",
      "1180 0.0017193262 [0.9518413] [0.1094761]\n",
      "1200 0.001561516 [0.95410454] [0.10433111]\n",
      "1220 0.0014181952 [0.95626146] [0.09942795]\n",
      "1240 0.0012880304 [0.958317] [0.0947552]\n",
      "1260 0.001169811 [0.960276] [0.09030209]\n",
      "1280 0.0010624415 [0.9621428] [0.08605821]\n",
      "1300 0.00096492394 [0.963922] [0.08201379]\n",
      "1320 0.0008763606 [0.96561754] [0.0781594]\n",
      "1340 0.0007959229 [0.9672334] [0.0744862]\n",
      "1360 0.000722871 [0.9687733] [0.07098563]\n",
      "1380 0.0006565211 [0.9702409] [0.06764957]\n",
      "1400 0.0005962627 [0.97163945] [0.06447028]\n",
      "1420 0.00054153596 [0.97297233] [0.06144037]\n",
      "1440 0.00049183134 [0.97424245] [0.05855288]\n",
      "1460 0.00044668862 [0.97545296] [0.05580113]\n",
      "1480 0.0004056903 [0.9766066] [0.05317869]\n",
      "1500 0.00036845505 [0.97770596] [0.05067951]\n",
      "1520 0.0003346358 [0.9787537] [0.04829778]\n",
      "1540 0.00030392295 [0.97975224] [0.04602796]\n",
      "1560 0.00027602562 [0.9807039] [0.04386475]\n",
      "1580 0.00025069262 [0.98161066] [0.04180325]\n",
      "1600 0.00022768103 [0.9824749] [0.03983866]\n",
      "1620 0.00020678522 [0.9832985] [0.0379664]\n",
      "1640 0.0001878051 [0.9840834] [0.03618211]\n",
      "1660 0.00017056677 [0.98483145] [0.0344817]\n",
      "1680 0.00015491205 [0.98554426] [0.03286119]\n",
      "1700 0.00014069451 [0.98622364] [0.03131685]\n",
      "1720 0.00012778128 [0.9868711] [0.02984508]\n",
      "1740 0.000116052 [0.9874881] [0.02844246]\n",
      "1760 0.00010540142 [0.9880761] [0.02710578]\n",
      "1780 9.572667e-05 [0.9886365] [0.02583192]\n",
      "1800 8.694101e-05 [0.9891705] [0.02461793]\n",
      "1820 7.8961435e-05 [0.98967934] [0.02346103]\n",
      "1840 7.171408e-05 [0.9901645] [0.02235852]\n",
      "1860 6.513137e-05 [0.9906268] [0.02130768]\n",
      "1880 5.915377e-05 [0.9910673] [0.02030626]\n",
      "1900 5.372355e-05 [0.9914871] [0.01935191]\n",
      "1920 4.8792102e-05 [0.9918872] [0.01844241]\n",
      "1940 4.4314667e-05 [0.99226844] [0.01757567]\n",
      "1960 4.0247276e-05 [0.9926318] [0.01674967]\n",
      "1980 3.655281e-05 [0.9929781] [0.0159625]\n",
      "2000 3.319788e-05 [0.99330807] [0.01521232]\n"
     ]
    }
   ],
   "source": [
    "# Fit the line\n",
    "for step in range(2001):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(cost), sess.run(W), sess.run(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961d9b84-5ba2-40af-a083-27665ef02efa",
   "metadata": {},
   "source": [
    "# Place Holder 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a42f3da9-988e-45e6-9f0a-292dcd93cb9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.05416252 [1.1584259] [0.59723353]\n",
      "20 0.041250844 [1.1314949] [0.6255745]\n",
      "40 0.03602457 [1.1228083] [0.6566243]\n",
      "60 0.03146054 [1.1147653] [0.68566114]\n",
      "80 0.027474726 [1.1072491] [0.7127965]\n",
      "100 0.023993827 [1.1002252] [0.7381548]\n",
      "120 0.020954024 [1.0936615] [0.7618523]\n",
      "140 0.018299295 [1.0875275] [0.78399795]\n",
      "160 0.015980901 [1.0817951] [0.8046933]\n",
      "180 0.013956241 [1.0764384] [0.82403314]\n",
      "200 0.01218809 [1.0714324] [0.8421064]\n",
      "220 0.010643937 [1.0667541] [0.8589961]\n",
      "240 0.009295432 [1.0623825] [0.8747796]\n",
      "260 0.008117773 [1.0582969] [0.8895294]\n",
      "280 0.0070893094 [1.054479] [0.90331334]\n",
      "300 0.0061911466 [1.0509111] [0.91619444]\n",
      "320 0.0054067704 [1.0475769] [0.9282321]\n",
      "340 0.0047217803 [1.0444611] [0.9394813]\n",
      "360 0.00412356 [1.0415493] [0.94999385]\n",
      "380 0.003601142 [1.0388281] [0.9598179]\n",
      "400 0.0031448945 [1.0362853] [0.96899855]\n",
      "420 0.002746468 [1.033909] [0.97757804]\n",
      "440 0.0023984946 [1.0316882] [0.9855956]\n",
      "460 0.002094626 [1.0296128] [0.993088]\n",
      "480 0.0018292489 [1.0276735] [1.0000899]\n",
      "500 0.0015974991 [1.0258611] [1.0066332]\n",
      "520 0.0013951042 [1.0241674] [1.0127478]\n",
      "540 0.001218353 [1.0225848] [1.0184618]\n",
      "560 0.001064001 [1.0211055] [1.0238018]\n",
      "580 0.00092920323 [1.0197234] [1.0287918]\n",
      "600 0.00081148715 [1.0184318] [1.0334555]\n",
      "620 0.0007086656 [1.0172247] [1.0378137]\n",
      "640 0.000618881 [1.0160965] [1.0418863]\n",
      "660 0.0005404695 [1.0150423] [1.0456924]\n",
      "680 0.00047199675 [1.0140572] [1.049249]\n",
      "700 0.00041220174 [1.0131366] [1.0525727]\n",
      "720 0.00035997725 [1.0122763] [1.0556788]\n",
      "740 0.00031436962 [1.0114722] [1.0585816]\n",
      "760 0.00027454307 [1.010721] [1.0612941]\n",
      "780 0.0002397567 [1.0100188] [1.0638288]\n",
      "800 0.0002093893 [1.0093627] [1.0661975]\n",
      "820 0.00018285963 [1.0087495] [1.0684112]\n",
      "840 0.00015969372 [1.0081764] [1.0704801]\n",
      "860 0.00013946214 [1.0076411] [1.0724133]\n",
      "880 0.00012179117 [1.0071406] [1.0742201]\n",
      "900 0.000106361134 [1.006673] [1.0759084]\n",
      "920 9.288621e-05 [1.006236] [1.0774863]\n",
      "940 8.1117294e-05 [1.0058277] [1.0789607]\n",
      "960 7.083889e-05 [1.0054457] [1.0803388]\n",
      "980 6.186359e-05 [1.0050892] [1.0816265]\n",
      "1000 5.4025575e-05 [1.0047559] [1.0828298]\n",
      "1020 4.7181275e-05 [1.0044444] [1.0839543]\n",
      "1040 4.1205152e-05 [1.0041534] [1.085005]\n",
      "1060 3.5982855e-05 [1.0038813] [1.0859871]\n",
      "1080 3.142544e-05 [1.0036272] [1.0869046]\n",
      "1100 2.7445567e-05 [1.0033897] [1.0877621]\n",
      "1120 2.3967013e-05 [1.0031676] [1.0885637]\n",
      "1140 2.0931793e-05 [1.0029603] [1.0893124]\n",
      "1160 1.827969e-05 [1.0027664] [1.0900122]\n",
      "1180 1.596428e-05 [1.0025853] [1.0906663]\n",
      "1200 1.3941761e-05 [1.002416] [1.0912775]\n",
      "1220 1.2175295e-05 [1.0022577] [1.0918489]\n",
      "1240 1.0632858e-05 [1.0021099] [1.0923827]\n",
      "1260 9.28581e-06 [1.0019717] [1.0928816]\n",
      "1280 8.10927e-06 [1.0018425] [1.0933478]\n",
      "1300 7.082497e-06 [1.001722] [1.0937834]\n",
      "1320 6.184478e-06 [1.0016091] [1.0941905]\n",
      "1340 5.4011384e-06 [1.0015038] [1.0945709]\n",
      "1360 4.717136e-06 [1.0014054] [1.0949261]\n",
      "1380 4.120169e-06 [1.0013134] [1.0952582]\n",
      "1400 3.5984624e-06 [1.0012274] [1.0955688]\n",
      "1420 3.1424056e-06 [1.001147] [1.0958589]\n",
      "1440 2.7447168e-06 [1.0010718] [1.09613]\n",
      "1460 2.3967043e-06 [1.0010017] [1.0963835]\n",
      "1480 2.0931298e-06 [1.000936] [1.0966203]\n",
      "1500 1.828014e-06 [1.0008749] [1.0968417]\n",
      "1520 1.596061e-06 [1.0008177] [1.0970485]\n",
      "1540 1.3941399e-06 [1.000764] [1.0972416]\n",
      "1560 1.2175293e-06 [1.0007141] [1.0974222]\n",
      "1580 1.0634461e-06 [1.0006673] [1.097591]\n",
      "1600 9.2870323e-07 [1.0006236] [1.0977488]\n",
      "1620 8.1107663e-07 [1.0005827] [1.0978961]\n",
      "1640 7.08504e-07 [1.0005445] [1.0980338]\n",
      "1660 6.1878944e-07 [1.0005089] [1.0981624]\n",
      "1680 5.4050525e-07 [1.0004756] [1.0982827]\n",
      "1700 4.7197517e-07 [1.0004444] [1.0983951]\n",
      "1720 4.1223643e-07 [1.0004154] [1.0985001]\n",
      "1740 3.600156e-07 [1.0003884] [1.0985984]\n",
      "1760 3.1438367e-07 [1.0003628] [1.0986902]\n",
      "1780 2.7465285e-07 [1.000339] [1.0987757]\n",
      "1800 2.3979146e-07 [1.000317] [1.0988559]\n",
      "1820 2.0940885e-07 [1.0002961] [1.0989308]\n",
      "1840 1.8286943e-07 [1.0002768] [1.0990007]\n",
      "1860 1.5970274e-07 [1.0002587] [1.0990663]\n",
      "1880 1.3966701e-07 [1.0002419] [1.099127]\n",
      "1900 1.2193219e-07 [1.000226] [1.0991842]\n",
      "1920 1.0657415e-07 [1.0002114] [1.0992376]\n",
      "1940 9.3017476e-08 [1.0001973] [1.0992873]\n",
      "1960 8.123084e-08 [1.0001845] [1.0993339]\n",
      "1980 7.102676e-08 [1.0001725] [1.0993774]\n",
      "2000 6.2002755e-08 [1.000161] [1.0994183]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "\n",
    "# Our hypothesis XW+b\n",
    "hypothesis = X * W + b\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Fit the line with new training data\n",
    "for step in range(2001):\n",
    "    cost_val, W_val, b_val, _ = sess.run([cost, W, b, train],\n",
    "                                         feed_dict={X: [1, 2, 3, 4, 5], \n",
    "                                                    Y: [2.1, 3.1, 4.1, 5.1, 6.1]})\n",
    "    if step % 20 == 0:\n",
    "        print(step, cost_val, W_val, b_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08070903-62a4-4310-a5c3-35e9ee33e008",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 2         \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 3 samples\n",
      "Epoch 1/200\n",
      "3/3 [==============================] - 0s 14ms/sample - loss: 12.8598\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.2041\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0506\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0464\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0442\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0421\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0401\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0382\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0364\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0347\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0330\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0314\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0299\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0285\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0272\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0259\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0247\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0235\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0224\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0213\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0203\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0193\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0184\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0175\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0167\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0159\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0152\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0144\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0137\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0131\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0125\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0119\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0113\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0108\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0103\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0098\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0093\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0089\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0085\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0080\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0077\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0073\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0070\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0066\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0063\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 0.0060\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0057\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0055\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0052\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0049\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 0.0047\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0045\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0043\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0041\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0039\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0037\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0035\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0034\n",
      "Epoch 59/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0032\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0030\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0029\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0028\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0026\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0025\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0024\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0023\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0022\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0021\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0020\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0019\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0018\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0017\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0016\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0015\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0015\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0014\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0013\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 0.0013\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0012\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kih\\Anaconda3\\envs\\tf_py36\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 0.0011\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 0.0010\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 9.9289e-04\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 9.4573e-04\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 9.0081e-04\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 8.5802e-04\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 8.1726e-04\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 7.7844e-04\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 7.4147e-04\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 7.0624e-04\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 6.7270e-04\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 6.4074e-04\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 6.1031e-04\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 5.8132e-04\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 5.5370e-04\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 5.2740e-04\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 5.0235e-04\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 4.7849e-04\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 4.5576e-04\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 4.3411e-04\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 4.1349e-04\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 3.9385e-04\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.7514e-04\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 314us/sample - loss: 3.5732e-04\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.4035e-04\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.2418e-04\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 3.0878e-04\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 2.9412e-04\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.8014e-04\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 2.6684e-04\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.5416e-04\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.4209e-04\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.3059e-04\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.1964e-04\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.0920e-04\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.9927e-04\n",
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.8980e-04\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.8078e-04\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.7220e-04\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.6402e-04\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.5623e-04\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.4881e-04\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.4174e-04\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 1.3501e-04\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 1.2859e-04\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 5ms/sample - loss: 1.2248e-04\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.1667e-04\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.1113e-04\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.0585e-04\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.0082e-04\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 9.6030e-05\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 9.1468e-05\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 8.7123e-05\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 8.2985e-05\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 7.9043e-05\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 7.5289e-05\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 7.1713e-05\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 6.8306e-05\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 6.5061e-05\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 6.1972e-05\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 5.9028e-05\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 5.6224e-05\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 5.3553e-05\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 5.1009e-05\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 4.8585e-05\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 4.6278e-05\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 4.4080e-05\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 4.1987e-05\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 3.9992e-05\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.8092e-05\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.6283e-05\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.4559e-05\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.2918e-05\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 3.1354e-05\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 2.9865e-05\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.8446e-05\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 2.7095e-05\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 2.5807e-05\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.4582e-05\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.3414e-05\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 2.2302e-05\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 2.1243e-05\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 2.0234e-05\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.9273e-05\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.8357e-05\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.7485e-05\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 1.6655e-05\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.5864e-05\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.5110e-05\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.4392e-05\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.3709e-05\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.3057e-05\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.2437e-05\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.1847e-05\n",
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.1284e-05\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 1.0748e-05\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 1.0237e-05\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 9.7506e-06\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 9.2876e-06\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 8.8468e-06\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 8.4262e-06\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 8.0259e-06\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 7.6449e-06\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 7.2814e-06\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 6.9360e-06\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 6.6064e-06\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 6.2926e-06\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 5.9939e-06\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 5.7090e-06\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 5.4378e-06\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 5.1794e-06\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 4.9335e-06\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 4.6993e-06\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 4.4760e-06\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 0s/sample - loss: 4.2635e-06\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 4.0610e-06\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.8681e-06\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 667us/sample - loss: 3.6843e-06\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 334us/sample - loss: 3.5091e-06\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 333us/sample - loss: 3.3425e-06\n",
      "[[4.9943485]\n",
      " [3.9964213]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kih\\Anaconda3\\envs\\tf_py36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "# Tensor Flow 2.0\n",
    "\n",
    "##x_train = [1, 2, 3, 4]\n",
    "##y_train = [0, -1, -2, -3]\n",
    "#\n",
    "#tf.model = tf.keras.Sequential()\n",
    "## units == output shape, input_dim == input shape\n",
    "#tf.model.add(tf.keras.layers.Dense(units=1, input_dim=1))\n",
    "#\n",
    "#sgd = tf.keras.optimizers.SGD(lr=0.1)  # SGD == standard gradient descendent, lr == learning rate\n",
    "#tf.model.compile(loss='mse', optimizer=sgd)  # mse == mean_squared_error, 1/m * sig (y'-y)^2\n",
    "#\n",
    "## prints summary of the model to the terminal\n",
    "#tf.model.summary()\n",
    "#\n",
    "## fit() executes training\n",
    "#tf.model.fit(x_train, y_train, epochs=200)\n",
    "#\n",
    "## predict() returns predicted value\n",
    "#y_predict = tf.model.predict(np.array([5, 4]))\n",
    "#print(y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
