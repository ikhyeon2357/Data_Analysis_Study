{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7216854e-f003-4bac-9193-8e923e31fd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kih\\Anaconda3\\envs\\tf_py36\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14804fa5-4a50-43b0-b87a-4f6d00e3f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a2a238-a478-4051-989d-9f82922e7409",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1558543 [[ 0.5807229   0.53629667  0.28503624]\n",
      " [-0.880366   -0.5175341  -0.27097937]\n",
      " [ 1.1865109   0.58328104 -0.3828085 ]]\n",
      "1 1.0075483 [[ 0.5547206   0.5424017   0.30493358]\n",
      " [-0.9547444  -0.49127546 -0.22285959]\n",
      " [ 1.0872434   0.63115525 -0.3314152 ]]\n",
      "2 0.92436826 [[ 0.5528882   0.5286323   0.3205353 ]\n",
      " [-0.90297264 -0.5720706  -0.19383623]\n",
      " [ 1.1160883   0.56790024 -0.2970051 ]]\n",
      "3 0.89032674 [[ 0.53469634  0.53762937  0.3297301 ]\n",
      " [-0.9394094  -0.5328238  -0.19664629]\n",
      " [ 1.0536007   0.62223166 -0.28884894]]\n",
      "4 0.87250215 [[ 0.5328474   0.52988255  0.33932585]\n",
      " [-0.89041984 -0.58170545 -0.19675417]\n",
      " [ 1.0803318   0.58640695 -0.27975532]]\n",
      "5 0.8590492 [[ 0.51894367  0.53647655  0.34663558]\n",
      " [-0.90588945 -0.55437213 -0.20861787]\n",
      " [ 1.0402896   0.62676066 -0.28006688]]\n",
      "6 0.8482194 [[ 0.5151779   0.5313864   0.35549155]\n",
      " [-0.86864805 -0.58820254 -0.21202885]\n",
      " [ 1.0560089   0.6048408  -0.27386636]]\n",
      "7 0.8391906 [[ 0.5031324   0.5358755   0.36304793]\n",
      " [-0.87600094 -0.57094026 -0.22193824]\n",
      " [ 1.0258435   0.6339838  -0.2728439 ]]\n",
      "8 0.83123213 [[ 0.49822268  0.5322326   0.37160054]\n",
      " [-0.8464812  -0.596053   -0.22634524]\n",
      " [ 1.0348635   0.61972076 -0.2676009 ]]\n",
      "9 0.8240837 [[ 0.48738742  0.535392    0.37927637]\n",
      " [-0.84913635 -0.58476895 -0.23497412]\n",
      " [ 1.0110015   0.6417479  -0.26576596]]\n",
      "10 0.8175034 [[ 0.4818037   0.5326472   0.3876049 ]\n",
      " [-0.82484    -0.604106   -0.23993337]\n",
      " [ 1.0159177   0.6322124  -0.2611467 ]]\n",
      "11 0.8113964 [[ 0.4718368   0.5349056   0.39531335]\n",
      " [-0.82455814 -0.59657896 -0.24774225]\n",
      " [ 0.9964722   0.64938295 -0.25887176]]\n",
      "12 0.80566204 [[ 0.46584344  0.5327502   0.40346214]\n",
      " [-0.80403465 -0.6118353  -0.25300938]\n",
      " [ 0.99875337  0.64292526 -0.25469527]]\n",
      "13 0.800256 [[ 0.45653328  0.5343653   0.41115722]\n",
      " [-0.80186814 -0.60676587 -0.26024535]\n",
      " [ 0.9825635   0.6566006  -0.25218073]]\n",
      "14 0.79512715 [[ 0.45029125  0.5326103   0.41915426]\n",
      " [-0.7841985  -0.6190106  -0.2656702 ]\n",
      " [ 0.9831096   0.6522104  -0.24833666]]\n",
      "15 0.7902502 [[ 0.4414975   0.53374887  0.42680943]\n",
      " [-0.7808136  -0.6155876  -0.27247822]\n",
      " [ 0.96941096  0.66327316 -0.24570073]]\n",
      "16 0.7855949 [[ 0.43510994  0.5322728   0.43467304]\n",
      " [-0.7653783  -0.62553555 -0.27796552]\n",
      " [ 0.9688033   0.66029984 -0.24211974]]\n",
      "17 0.7811445 [[ 0.42673486  0.5330487   0.44227222]\n",
      " [-0.7612126  -0.62323064 -0.2844361 ]\n",
      " [ 0.9570676   0.6693525  -0.23943667]]\n",
      "18 0.77687865 [[ 0.4202701   0.5317708   0.45001486]\n",
      " [-0.7475742  -0.6313811  -0.289924  ]\n",
      " [ 0.9556949   0.6673626  -0.23607409]]\n",
      "19 0.7727852 [[ 0.4122429   0.5322649   0.457548  ]\n",
      " [-0.7429228  -0.6298402  -0.29611632]\n",
      " [ 0.945543    0.6748329  -0.23339249]]\n",
      "20 0.7688494 [[ 0.40574715  0.53113014  0.46517852]\n",
      " [-0.73076063 -0.63655484 -0.30156383]\n",
      " [ 0.9436721   0.6735301  -0.23021881]]\n",
      "21 0.7650613 [[ 0.39801478  0.53140175  0.47263923]\n",
      " [-0.72582614 -0.6355352  -0.30751795]\n",
      " [ 0.93482286  0.67973214 -0.22757156]]\n",
      "22 0.7614097 [[ 0.3915199   0.5303718   0.48016408]\n",
      " [-0.71489775 -0.6410839  -0.3128976 ]\n",
      " [ 0.9326403   0.67891    -0.22456685]]\n",
      "23 0.7578865 [[ 0.38404158  0.5304658   0.48754838]\n",
      " [-0.7098212  -0.6404166  -0.3186414 ]\n",
      " [ 0.9248795   0.68408054 -0.22197656]]\n",
      "24 0.7544827 [[ 0.37756965  0.5295136   0.49497247]\n",
      " [-0.6999383  -0.64500624 -0.32393467]\n",
      " [ 0.92251766  0.68359286 -0.21912704]]\n",
      "25 0.7511915 [[ 0.37031317  0.5294646   0.502278  ]\n",
      " [-0.6948188  -0.6445722  -0.32948825]\n",
      " [ 0.91567826  0.6879147  -0.21660954]]\n",
      "26 0.7480053 [[ 0.36387956  0.528571    0.50960517]\n",
      " [-0.685832   -0.6483646  -0.33468258]\n",
      " [ 0.91323185  0.68765694 -0.21390533]]\n",
      "27 0.74491847 [[ 0.356819    0.52840626  0.51683044]\n",
      " [-0.6807392  -0.6480794  -0.34006062]\n",
      " [ 0.9071811   0.69127405 -0.21147166]]\n",
      "28 0.74192476 [[ 0.35043436  0.5275574   0.52406394]\n",
      " [-0.67252797 -0.6512038  -0.34514752]\n",
      " [ 0.9047183   0.6911707  -0.2089055 ]]\n",
      "29 0.7390193 [[ 0.34354854  0.52729875  0.5312084 ]\n",
      " [-0.6675108  -0.65100724 -0.35036126]\n",
      " [ 0.89934874  0.6941982  -0.20656346]]\n",
      "30 0.7361966 [[ 0.3372201   0.5264846   0.53835094]\n",
      " [-0.65997595 -0.65356827 -0.3553351 ]\n",
      " [ 0.89691865  0.69419456 -0.20412974]]\n",
      "31 0.7334526 [[ 0.33049136  0.5261498   0.5454145 ]\n",
      " [-0.65506876 -0.6534174  -0.36039314]\n",
      " [ 0.892142    0.6967261  -0.20188461]]\n",
      "32 0.73078287 [[ 0.32422403  0.5253632   0.5524684 ]\n",
      " [-0.64812785 -0.6555011  -0.36525032]\n",
      " [ 0.88978004  0.6967823  -0.19957885]]\n",
      "33 0.72818375 [[ 0.31763756  0.5249668   0.55945134]\n",
      " [-0.64335406 -0.6553656  -0.37015963]\n",
      " [ 0.8855231   0.6988947  -0.19743422]]\n",
      "34 0.7256512 [[ 0.3114344   0.5242025   0.56641877]\n",
      " [-0.636938   -0.6570432  -0.37489805]\n",
      " [ 0.8832541   0.69898206 -0.19525264]]\n",
      "35 0.7231822 [[ 0.30497763  0.5237565   0.5733216 ]\n",
      " [-0.632313   -0.65690196 -0.37966424]\n",
      " [ 0.8794554   0.7007388  -0.19321069]]\n",
      "36 0.7207736 [[ 0.29884037  0.52301085  0.5802045 ]\n",
      " [-0.62636316 -0.65823317 -0.3842829 ]\n",
      " [ 0.87729675  0.7008367  -0.19115001]]\n",
      "37 0.7184223 [[ 0.29250255  0.52252525  0.5870279 ]\n",
      " [-0.62189674 -0.65807164 -0.3889108 ]\n",
      " [ 0.87390435  0.702291   -0.18921189]]\n",
      "38 0.7161256 [[ 0.28643203  0.52179563  0.5938281 ]\n",
      " [-0.6163631  -0.65910673 -0.39340937]\n",
      " [ 0.8718676   0.7023849  -0.18726903]]\n",
      "39 0.71388113 [[ 0.28020382  0.52127886  0.60057306]\n",
      " [-0.61206055 -0.6589155  -0.3979031 ]\n",
      " [ 0.86883724  0.70358133 -0.18543512]]\n",
      "40 0.71168643 [[ 0.2742001   0.5205634   0.60729223]\n",
      " [-0.60690016 -0.659697   -0.402282  ]\n",
      " [ 0.8669296   0.70366114 -0.18360728]]\n",
      "41 0.7095392 [[ 0.26807344  0.5200226   0.6139597 ]\n",
      " [-0.6027635  -0.6594704  -0.4066453 ]\n",
      " [ 0.86422336  0.70463735 -0.1818773 ]]\n",
      "42 0.70743763 [[ 0.26213607  0.51932013  0.62059957]\n",
      " [-0.5979394  -0.6600345  -0.4109053 ]\n",
      " [ 0.8624487   0.7046965  -0.18016173]]\n",
      "43 0.7053795 [[ 0.25610387  0.51876116  0.6271907 ]\n",
      " [-0.5939682  -0.65976936 -0.41514155]\n",
      " [ 0.8600339   0.70548445 -0.17853492]]\n",
      "44 0.70336306 [[ 0.250232    0.518071    0.63375276]\n",
      " [-0.58944815 -0.66014713 -0.4192838 ]\n",
      " [ 0.85839367  0.7055187  -0.1769289 ]]\n",
      "45 0.7013867 [[ 0.24428809  0.517499    0.6402687 ]\n",
      " [-0.5856405  -0.65984243 -0.42339614]\n",
      " [ 0.856242    0.7061456  -0.17540412]]\n",
      "46 0.6994487 [[ 0.23848058  0.51682067  0.6467545 ]\n",
      " [-0.5813965  -0.6600604  -0.42742214]\n",
      " [ 0.8547357   0.70615274 -0.17390497]]\n",
      "47 0.6975476 [[ 0.23261942  0.51623994  0.6531964 ]\n",
      " [-0.5777491  -0.6597164  -0.43141356]\n",
      " [ 0.85282236  0.7066418  -0.17248073]]\n",
      "48 0.695682 [[ 0.22687499  0.5155732   0.6596075 ]\n",
      " [-0.5737566  -0.65979755 -0.43532497]\n",
      " [ 0.85144824  0.70662093 -0.17108576]]\n",
      "49 0.69385064 [[ 0.22109172  0.5149874   0.6659766 ]\n",
      " [-0.570265   -0.6594157  -0.43919834]\n",
      " [ 0.8497518   0.706992   -0.16976032]]\n",
      "50 0.6920519 [[ 0.21540889  0.51433235  0.67231447]\n",
      " [-0.5665025  -0.65937954 -0.442997  ]\n",
      " [ 0.84850687  0.7069434  -0.16846684]]\n",
      "51 0.69028497 [[ 0.20969915  0.5137446   0.67861193]\n",
      " [-0.56316185 -0.6589621  -0.44675514]\n",
      " [ 0.8470083   0.70721334 -0.16723825]]\n",
      "52 0.68854845 [[ 0.20407635  0.5131013   0.68487805]\n",
      " [-0.55961037 -0.6588256  -0.4504431 ]\n",
      " [ 0.84588903  0.70713794 -0.16604358]]\n",
      "53 0.6868416 [[ 0.19843625  0.51251423  0.69110525]\n",
      " [-0.5564154  -0.65837497 -0.4540887 ]\n",
      " [ 0.8445716   0.7073215  -0.16490974]]\n",
      "54 0.685163 [[ 0.19287188  0.51188284  0.697301  ]\n",
      " [-0.5530581  -0.65815294 -0.45766798]\n",
      " [ 0.8435738   0.7072207  -0.1638111 ]]\n",
      "55 0.683512 [[ 0.18729791  0.5112987   0.7034591 ]\n",
      " [-0.55000305 -0.65767217 -0.46120378]\n",
      " [ 0.8424228   0.70733035 -0.16276976]]\n",
      "56 0.6818874 [[ 0.18179034  0.51067954  0.70958585]\n",
      " [-0.54682505 -0.65737724 -0.46467665]\n",
      " [ 0.84154195  0.7072059  -0.16176446]]\n",
      "57 0.6802885 [[ 0.17627929  0.51010025  0.7156762 ]\n",
      " [-0.54390436 -0.6568693  -0.46810532]\n",
      " [ 0.8405441   0.7072525  -0.16081326]]\n",
      "58 0.6787145 [[ 0.1708269   0.5094935   0.7217353 ]\n",
      " [-0.5408923  -0.6565126  -0.47147405]\n",
      " [ 0.83977556  0.70710635 -0.15989853]]\n",
      "59 0.67716444 [[ 0.1653759   0.5089207   0.7277591 ]\n",
      " [-0.53810024 -0.65598047 -0.47479826]\n",
      " [ 0.83891916  0.7070993  -0.15903509]]\n",
      "60 0.6756377 [[ 0.15997706  0.5083267   0.73375195]\n",
      " [-0.53524214 -0.65557164 -0.47806513]\n",
      " [ 0.83825815  0.70693344 -0.15820818]]\n",
      "61 0.6741337 [[ 0.15458347  0.5077618   0.7397105 ]\n",
      " [-0.532573   -0.6550184  -0.4812875 ]\n",
      " [ 0.8375326   0.7068808  -0.15742998]]\n",
      "62 0.67265135 [[ 0.14923659  0.50718075  0.74563843]\n",
      " [-0.5298582  -0.65456575 -0.48445496]\n",
      " [ 0.8369742   0.70669734 -0.15668815]]\n",
      "63 0.67119026 [[ 0.14389797  0.5066248   0.751533  ]\n",
      " [-0.5273064  -0.6539944  -0.48757812]\n",
      " [ 0.83637     0.7066061  -0.15599267]]\n",
      "64 0.6697499 [[ 0.1386015   0.506057    0.75739723]\n",
      " [-0.52472514 -0.6535052  -0.49064857]\n",
      " [ 0.83590955  0.70640707 -0.15533322]]\n",
      "65 0.6683295 [[ 0.13331562  0.5055111   0.763229  ]\n",
      " [-0.52228534 -0.65291846 -0.4936751 ]\n",
      " [ 0.8354181   0.7062832  -0.1547179 ]]\n",
      "66 0.66692847 [[ 0.12806804  0.5049568   0.76903087]\n",
      " [-0.51982886 -0.65239906 -0.49665096]\n",
      " [ 0.8350509   0.70607066 -0.15413809]]\n",
      "67 0.66554624 [[ 0.12283286  0.5044217   0.7748011 ]\n",
      " [-0.51749575 -0.6517996  -0.4995835 ]\n",
      " [ 0.8346644   0.70591944 -0.1536004 ]]\n",
      "68 0.66418236 [[ 0.11763272  0.5038811   0.78054184]\n",
      " [-0.51515615 -0.65125555 -0.5024672 ]\n",
      " [ 0.83438575  0.7056952  -0.15309751]]\n",
      "69 0.66283643 [[ 0.11244633  0.5033576   0.7862517 ]\n",
      " [-0.51292473 -0.65064585 -0.50530833]\n",
      " [ 0.8340972   0.7055211  -0.15263486]]\n",
      "70 0.66150755 [[ 0.1072922   0.5028308   0.79193264]\n",
      " [-0.5106947  -0.6500819  -0.50810236]\n",
      " [ 0.8339027   0.705287   -0.15220627]]\n",
      "71 0.6601957 [[ 0.10215282  0.5023194   0.7975834 ]\n",
      " [-0.50856006 -0.6494643  -0.51085454]\n",
      " [ 0.8337056   0.7050939  -0.15181611]]\n",
      "72 0.6589004 [[ 0.09704333  0.5018067   0.8032056 ]\n",
      " [-0.506433   -0.64888453 -0.51356137]\n",
      " [ 0.83359104  0.70485157 -0.15145917]]\n",
      "73 0.65762067 [[ 0.09194932  0.50130785  0.80879843]\n",
      " [-0.50439054 -0.6482612  -0.5162272 ]\n",
      " [ 0.8334795   0.7046429  -0.15113896]]\n",
      "74 0.6563568 [[ 0.08688315  0.50080925  0.8143632 ]\n",
      " [-0.5023604  -0.6476693  -0.5188492 ]\n",
      " [ 0.83344066  0.7043938  -0.15085107]]\n",
      "75 0.6551081 [[ 0.08183297  0.5003234   0.8198992 ]\n",
      " [-0.5004056  -0.64704216 -0.52143115]\n",
      " [ 0.83340925  0.7041725  -0.15059832]]\n",
      "76 0.6538739 [[ 0.07680884  0.4998391   0.8254077 ]\n",
      " [-0.4984668  -0.6464413  -0.52397084]\n",
      " [ 0.8334422   0.70391816 -0.15037693]]\n",
      "77 0.6526543 [[ 0.07180103  0.49936652  0.83088803]\n",
      " [-0.49659547 -0.64581203 -0.5264714 ]\n",
      " [ 0.8334859   0.70368665 -0.15018912]]\n",
      "78 0.6514486 [[ 0.06681774  0.4988965   0.8363413 ]\n",
      " [-0.4947428  -0.645205   -0.5289311 ]\n",
      " [ 0.83358693  0.7034282  -0.15003169]]\n",
      "79 0.6502565 [[ 0.06185093  0.49843746  0.8417672 ]\n",
      " [-0.49295104 -0.64457524 -0.53135264]\n",
      " [ 0.8337011   0.70318884 -0.14990643]]\n",
      "80 0.64907795 [[ 0.05690731  0.49798182  0.8471665 ]\n",
      " [-0.49117973 -0.6439644  -0.53373474]\n",
      " [ 0.8338666   0.7029275  -0.14981054]]\n",
      "81 0.64791226 [[ 0.05198023  0.49753648  0.8525389 ]\n",
      " [-0.4894636  -0.6433355  -0.53607976]\n",
      " [ 0.83404696  0.70268196 -0.1497454 ]]\n",
      "82 0.6467593 [[ 0.04707516  0.4970952   0.85788524]\n",
      " [-0.4877693  -0.64272296 -0.53838664]\n",
      " [ 0.8342735   0.7024186  -0.14970863]]\n",
      "83 0.6456187 [[ 0.04218659  0.4966637   0.8632053 ]\n",
      " [-0.48612523 -0.6420962  -0.54065746]\n",
      " [ 0.8345161   0.70216864 -0.14970127]]\n",
      "84 0.6444902 [[ 0.03731899  0.4962368   0.8684998 ]\n",
      " [-0.4845038  -0.64148366 -0.54289144]\n",
      " [ 0.8348005   0.7019043  -0.14972126]]\n",
      "85 0.6433735 [[ 0.03246779  0.49581918  0.8737686 ]\n",
      " [-0.4829283  -0.64086026 -0.5450903 ]\n",
      " [ 0.83510166  0.7016512  -0.1497694 ]]\n",
      "86 0.6422683 [[ 0.02763663  0.49540663  0.87901235]\n",
      " [-0.481376   -0.64024925 -0.5472536 ]\n",
      " [ 0.8354407   0.70138663 -0.14984387]]\n",
      "87 0.64117444 [[ 0.02282172  0.49500299  0.8842309 ]\n",
      " [-0.47986582 -0.63963014 -0.5493829 ]\n",
      " [ 0.8357971   0.70113164 -0.14994529]]\n",
      "88 0.64009154 [[ 0.018026    0.49460477  0.88942486]\n",
      " [-0.47837904 -0.63902205 -0.5514778 ]\n",
      " [ 0.8361879   0.70086753 -0.15007201]]\n",
      "89 0.6390195 [[ 0.01324633  0.4942151   0.8945942 ]\n",
      " [-0.47693118 -0.638408   -0.5535397 ]\n",
      " [ 0.8365962   0.70061165 -0.15022448]]\n",
      "90 0.6379579 [[ 0.00848512  0.4938311   0.8997394 ]\n",
      " [-0.47550657 -0.637804   -0.55556834]\n",
      " [ 0.8370361   0.70034856 -0.1504013 ]]\n",
      "91 0.6369066 [[ 0.00373973  0.49345538  0.9048605 ]\n",
      " [-0.47411805 -0.6371958  -0.55756503]\n",
      " [ 0.8374934   0.7000927  -0.15060271]]\n",
      "92 0.63586533 [[-0.0009879   0.49308556  0.90995795]\n",
      " [-0.47275263 -0.6365967  -0.5595296 ]\n",
      " [ 0.8379797   0.6998312  -0.15082747]]\n",
      "93 0.63483405 [[-0.00569994  0.49272376  0.9150318 ]\n",
      " [-0.47142062 -0.63599515 -0.5614632 ]\n",
      " [ 0.8384833   0.69957584 -0.15107572]]\n",
      "94 0.6338123 [[-0.01039487  0.49236804  0.92008245]\n",
      " [-0.4701115  -0.6354017  -0.56336576]\n",
      " [ 0.83901334  0.69931644 -0.1513464 ]]\n",
      "95 0.6328 [[-0.01507446  0.49202007  0.92511   ]\n",
      " [-0.46883336 -0.6348073  -0.56523836]\n",
      " [ 0.83956057  0.69906235 -0.15163952]]\n",
      "96 0.6317969 [[-0.01973751  0.4916783   0.9301148 ]\n",
      " [-0.4675777  -0.6342203  -0.567081  ]\n",
      " [ 0.84013224  0.6988053  -0.15195413]]\n",
      "97 0.63080287 [[-0.02438551  0.4913441   0.935097  ]\n",
      " [-0.46635106 -0.6336333  -0.56889457]\n",
      " [ 0.8407206   0.69855297 -0.15229018]]\n",
      "98 0.6298177 [[-0.02901748  0.49101618  0.94005686]\n",
      " [-0.4651463  -0.63305336 -0.5706793 ]\n",
      " [ 0.8413316   0.6982986  -0.1526468 ]]\n",
      "99 0.62884116 [[-0.03363468  0.49069563  0.9449946 ]\n",
      " [-0.46396875 -0.6324743  -0.5724359 ]\n",
      " [ 0.8419588   0.6980484  -0.15302385]]\n",
      "100 0.6278732 [[-0.03823636  0.49038142  0.9499105 ]\n",
      " [-0.46281248 -0.63190186 -0.5741646 ]\n",
      " [ 0.842607    0.69779694 -0.1534206 ]]\n",
      "101 0.62691355 [[-0.04282355  0.49007443  0.9548047 ]\n",
      " [-0.46168178 -0.631331   -0.57586616]\n",
      " [ 0.84327096  0.6975493  -0.15383688]]\n",
      "102 0.6259619 [[-0.04739568  0.4897738   0.95967746]\n",
      " [-0.46057183 -0.6307664  -0.57754076]\n",
      " [ 0.8439543   0.697301   -0.15427198]]\n",
      "103 0.6250185 [[-0.05195359  0.48948023  0.9645289 ]\n",
      " [-0.45948583 -0.630204   -0.5791891 ]\n",
      " [ 0.84465295  0.69705606 -0.1547257 ]]\n",
      "104 0.62408274 [[-0.05649687  0.48919302  0.9693594 ]\n",
      " [-0.45841992 -0.6296476  -0.5808115 ]\n",
      " [ 0.84536976  0.69681096 -0.15519741]]\n",
      "105 0.6231549 [[-0.06102625  0.48891276  0.974169  ]\n",
      " [-0.45737675 -0.6290938  -0.5824085 ]\n",
      " [ 0.8461011   0.6965691  -0.15568687]]\n",
      "106 0.62223434 [[-0.06554136  0.48863882  0.9789581 ]\n",
      " [-0.45635292 -0.6285458  -0.5839803 ]\n",
      " [ 0.84684944  0.6963273  -0.15619348]]\n",
      "107 0.6213213 [[-0.07004287  0.4883717   0.9837267 ]\n",
      " [-0.4553506  -0.62800074 -0.5855277 ]\n",
      " [ 0.8476117   0.6960886  -0.15671705]]\n",
      "108 0.62041557 [[-0.07453049  0.48811087  0.98847514]\n",
      " [-0.45436692 -0.6274613  -0.58705086]\n",
      " [ 0.84839     0.6958503  -0.15725699]]\n",
      "109 0.61951685 [[-0.07900478  0.48785675  0.9932036 ]\n",
      " [-0.45340362 -0.6269251  -0.5885503 ]\n",
      " [ 0.84918153  0.6956148  -0.15781306]]\n",
      "110 0.6186252 [[-0.08346554  0.48760888  0.9979122 ]\n",
      " [-0.4524583  -0.62639433 -0.59002644]\n",
      " [ 0.84998804  0.69538003 -0.15838474]]\n",
      "111 0.61774045 [[-0.08791324  0.48736757  1.0026013 ]\n",
      " [-0.45153233 -0.62586707 -0.59147966]\n",
      " [ 0.85080725  0.6951478  -0.15897177]]\n",
      "112 0.6168624 [[-0.09234774  0.48713246  1.0072709 ]\n",
      " [-0.45062363 -0.62534505 -0.59291035]\n",
      " [ 0.8516405   0.6949165  -0.15957372]]\n",
      "113 0.615991 [[-0.09676947  0.48690382  1.0119213 ]\n",
      " [-0.44973338 -0.62482667 -0.594319  ]\n",
      " [ 0.8524859   0.69468766 -0.16019028]]\n",
      "114 0.6151261 [[-0.10117831  0.4866813   1.0165526 ]\n",
      " [-0.44885972 -0.6243135  -0.59570587]\n",
      " [ 0.85334444  0.69445986 -0.16082105]]\n",
      "115 0.6142676 [[-0.10557464  0.48646516  1.021165  ]\n",
      " [-0.4480036  -0.62380403 -0.5970714 ]\n",
      " [ 0.85421455  0.69423443 -0.16146573]]\n",
      "116 0.6134154 [[-0.10995838  0.48625508  1.0257589 ]\n",
      " [-0.4471634  -0.62329966 -0.598416  ]\n",
      " [ 0.8550971   0.6940101  -0.16212392]]\n",
      "117 0.6125692 [[-0.11432988  0.48605126  1.0303342 ]\n",
      " [-0.44634    -0.62279904 -0.59973997]\n",
      " [ 0.8559906   0.69378805 -0.16279535]]\n",
      "118 0.61172926 [[-0.11868908  0.48585343  1.0348912 ]\n",
      " [-0.44553185 -0.62230337 -0.60104376]\n",
      " [ 0.8568958   0.6935671  -0.16347963]]\n",
      "119 0.6108953 [[-0.12303628  0.48566175  1.0394301 ]\n",
      " [-0.44473967 -0.62181157 -0.6023277 ]\n",
      " [ 0.85781145  0.69334835 -0.16417651]]\n",
      "120 0.610067 [[-0.12737146  0.485476    1.043951  ]\n",
      " [-0.44396225 -0.6213246  -0.6035921 ]\n",
      " [ 0.85873806  0.69313085 -0.1648856 ]]\n",
      "121 0.6092446 [[-0.13169488  0.48529628  1.0484542 ]\n",
      " [-0.4432     -0.62084156 -0.60483736]\n",
      " [ 0.85967463  0.6929153  -0.16560665]]\n",
      "122 0.6084279 [[-0.13600656  0.4851224   1.0529397 ]\n",
      " [-0.44245195 -0.6203632  -0.6060638 ]\n",
      " [ 0.8606215   0.69270116 -0.16633934]]\n",
      "123 0.6076167 [[-0.14030671  0.48495448  1.0574077 ]\n",
      " [-0.4417183  -0.61988884 -0.60727173]\n",
      " [ 0.8615779   0.6924888  -0.16708338]]\n",
      "124 0.60681105 [[-0.14459538  0.48479235  1.0618585 ]\n",
      " [-0.44099844 -0.6194189  -0.60846156]\n",
      " [ 0.86254394  0.6922779  -0.16783848]]\n",
      "125 0.60601085 [[-0.14887275  0.484636    1.0662923 ]\n",
      " [-0.44029224 -0.6189531  -0.60963356]\n",
      " [ 0.8635191   0.6920687  -0.16860436]]\n",
      "126 0.6052159 [[-0.15313888  0.4844854   1.070709  ]\n",
      " [-0.43959928 -0.61849165 -0.610788  ]\n",
      " [ 0.86450326  0.69186085 -0.1693807 ]]\n",
      "127 0.60442615 [[-0.15739393  0.4843405   1.0751089 ]\n",
      " [-0.4389195  -0.6180341  -0.61192524]\n",
      " [ 0.865496    0.69165474 -0.1701673 ]]\n",
      "128 0.6036416 [[-0.16163796  0.4842012   1.0794922 ]\n",
      " [-0.43825227 -0.61758095 -0.61304563]\n",
      " [ 0.8664974   0.69144994 -0.17096385]]\n",
      "129 0.6028621 [[-0.16587116  0.48406756  1.0838591 ]\n",
      " [-0.43759772 -0.6171317  -0.61414945]\n",
      " [ 0.8675068   0.69124675 -0.17177011]]\n",
      "130 0.6020876 [[-0.17009355  0.48393944  1.0882096 ]\n",
      " [-0.43695527 -0.61668664 -0.61523694]\n",
      " [ 0.8685244   0.69104487 -0.17258582]]\n",
      "131 0.6013181 [[-0.1743053   0.48381686  1.092544  ]\n",
      " [-0.43632486 -0.6162455  -0.61630845]\n",
      " [ 0.86954963  0.69084454 -0.17341073]]\n",
      "132 0.60055333 [[-0.1785065   0.48369974  1.0968623 ]\n",
      " [-0.43570614 -0.6158084  -0.6173642 ]\n",
      " [ 0.8705825   0.6906455  -0.17424458]]\n",
      "133 0.59979343 [[-0.18269724  0.48358804  1.1011648 ]\n",
      " [-0.43509895 -0.6153753  -0.61840457]\n",
      " [ 0.8716227   0.6904479  -0.17508717]]\n",
      "134 0.5990381 [[-0.18687762  0.4834817   1.1054516 ]\n",
      " [-0.43450293 -0.6149461  -0.61942977]\n",
      " [ 0.87267005  0.6902516  -0.17593823]]\n",
      "135 0.5982876 [[-0.19104777  0.4833807   1.1097227 ]\n",
      " [-0.433918   -0.6145207  -0.62044007]\n",
      " [ 0.87372434  0.6900567  -0.17679758]]\n",
      "136 0.59754145 [[-0.19520777  0.483285    1.1139784 ]\n",
      " [-0.43334386 -0.6140992  -0.62143576]\n",
      " [ 0.87478536  0.689863   -0.17766494]]\n",
      "137 0.59679997 [[-0.19935772  0.48319453  1.1182188 ]\n",
      " [-0.43278027 -0.6136815  -0.6224171 ]\n",
      " [ 0.87585294  0.68967056 -0.17854011]]\n",
      "138 0.5960628 [[-0.20349771  0.48310927  1.122444  ]\n",
      " [-0.43222702 -0.6132675  -0.6233843 ]\n",
      " [ 0.8769269   0.6894794  -0.1794229 ]]\n",
      "139 0.5953301 [[-0.20762783  0.48302916  1.1266543 ]\n",
      " [-0.4316839  -0.6128572  -0.6243377 ]\n",
      " [ 0.87800705  0.68928945 -0.18031308]]\n",
      "140 0.59460163 [[-0.21174818  0.48295417  1.1308496 ]\n",
      " [-0.43115076 -0.6124506  -0.6252774 ]\n",
      " [ 0.8790932   0.6891007  -0.18121044]]\n",
      "141 0.59387743 [[-0.21585885  0.48288423  1.1350302 ]\n",
      " [-0.43062735 -0.6120476  -0.6262038 ]\n",
      " [ 0.88018525  0.688913   -0.1821148 ]]\n",
      "142 0.59315753 [[-0.21995993  0.48281932  1.1391962 ]\n",
      " [-0.43011346 -0.6116482  -0.62711704]\n",
      " [ 0.8812829   0.6887265  -0.18302596]]\n",
      "143 0.5924417 [[-0.2240515   0.4827594   1.1433476 ]\n",
      " [-0.42960894 -0.6112523  -0.6280174 ]\n",
      " [ 0.8823861   0.68854105 -0.18394372]]\n",
      "144 0.59173006 [[-0.22813366  0.4827044   1.1474848 ]\n",
      " [-0.42911354 -0.61086    -0.6289051 ]\n",
      " [ 0.8834947   0.68835664 -0.18486789]]\n",
      "145 0.5910224 [[-0.23220651  0.48265433  1.1516078 ]\n",
      " [-0.42862722 -0.610471   -0.6297804 ]\n",
      " [ 0.8846084   0.68817335 -0.1857983 ]]\n",
      "146 0.59031856 [[-0.23627008  0.4826091   1.1557165 ]\n",
      " [-0.42814964 -0.61008555 -0.6306435 ]\n",
      " [ 0.88572717  0.687991   -0.18673477]]\n",
      "147 0.58961874 [[-0.24032451  0.48256868  1.1598114 ]\n",
      " [-0.4276807  -0.6097034  -0.6314945 ]\n",
      " [ 0.88685083  0.6878097  -0.18767712]]\n",
      "148 0.58892286 [[-0.24436985  0.48253304  1.1638924 ]\n",
      " [-0.4272202  -0.60932463 -0.6323338 ]\n",
      " [ 0.88797927  0.68762934 -0.18862519]]\n",
      "149 0.5882308 [[-0.24840619  0.4825021   1.1679597 ]\n",
      " [-0.42676798 -0.6089492  -0.6331615 ]\n",
      " [ 0.88911235  0.6874499  -0.18957879]]\n",
      "150 0.5875424 [[-0.2524336   0.48247588  1.1720133 ]\n",
      " [-0.42632395 -0.6085769  -0.6339778 ]\n",
      " [ 0.89024985  0.6872714  -0.19053778]]\n",
      "151 0.5868578 [[-0.25645217  0.4824543   1.1760534 ]\n",
      " [-0.42588782 -0.6082079  -0.6347829 ]\n",
      " [ 0.89139175  0.68709373 -0.19150199]]\n",
      "152 0.5861769 [[-0.260462    0.48243734  1.1800802 ]\n",
      " [-0.42545956 -0.60784197 -0.6355771 ]\n",
      " [ 0.89253783  0.68691695 -0.19247127]]\n",
      "153 0.5854996 [[-0.2644631   0.4824249   1.1840937 ]\n",
      " [-0.42503887 -0.6074793  -0.63636047]\n",
      " [ 0.893688    0.68674093 -0.19344546]]\n",
      "154 0.5848259 [[-0.2684556   0.48241705  1.1880941 ]\n",
      " [-0.42462578 -0.60711956 -0.63713324]\n",
      " [ 0.8948421   0.6865658  -0.19442444]]\n",
      "155 0.5841557 [[-0.27243954  0.48241365  1.1920815 ]\n",
      " [-0.42422    -0.606763   -0.6378956 ]\n",
      " [ 0.8960001   0.6863914  -0.19540803]]\n",
      "156 0.58348906 [[-0.27641502  0.4824147   1.1960559 ]\n",
      " [-0.42382148 -0.6064094  -0.63864774]\n",
      " [ 0.8971618   0.68621784 -0.1963961 ]]\n",
      "157 0.58282584 [[-0.28038207  0.48242015  1.2000175 ]\n",
      " [-0.42342997 -0.6060588  -0.6393898 ]\n",
      " [ 0.8983271   0.68604493 -0.19738851]]\n",
      "158 0.5821661 [[-0.2843408   0.48242998  1.2039664 ]\n",
      " [-0.4230455  -0.60571104 -0.640122  ]\n",
      " [ 0.8994959   0.6858728  -0.19838513]]\n",
      "159 0.5815096 [[-0.28829128  0.48244414  1.2079027 ]\n",
      " [-0.42266777 -0.60536623 -0.6408445 ]\n",
      " [ 0.9006681   0.6857013  -0.19938584]]\n",
      "160 0.58085656 [[-0.29223356  0.48246258  1.2118266 ]\n",
      " [-0.42229676 -0.6050243  -0.6415575 ]\n",
      " [ 0.90184355  0.6855305  -0.20039049]]\n",
      "161 0.5802068 [[-0.2961677   0.48248526  1.215738  ]\n",
      " [-0.42193228 -0.6046851  -0.6422611 ]\n",
      " [ 0.9030222   0.6853603  -0.20139895]]\n",
      "162 0.5795602 [[-0.3000938   0.48251218  1.2196373 ]\n",
      " [-0.42157423 -0.6043488  -0.6429555 ]\n",
      " [ 0.90420395  0.6851908  -0.20241113]]\n",
      "163 0.57891697 [[-0.30401188  0.48254326  1.2235243 ]\n",
      " [-0.42122248 -0.6040152  -0.6436408 ]\n",
      " [ 0.90538865  0.6850218  -0.20342687]]\n",
      "164 0.5782768 [[-0.30792204  0.4825785   1.2273992 ]\n",
      " [-0.42087695 -0.60368425 -0.64431727]\n",
      " [ 0.9065762   0.6848535  -0.20444609]]\n",
      "165 0.5776398 [[-0.31182432  0.4826178   1.2312622 ]\n",
      " [-0.42053744 -0.603356   -0.644985  ]\n",
      " [ 0.9077666   0.68468565 -0.20546865]]\n",
      "166 0.577006 [[-0.31571883  0.4826612   1.2351133 ]\n",
      " [-0.42020395 -0.6030304  -0.6456442 ]\n",
      " [ 0.90895957  0.6845184  -0.20649444]]\n",
      "167 0.57637525 [[-0.31960556  0.4827086   1.2389526 ]\n",
      " [-0.4198762  -0.60270745 -0.6462949 ]\n",
      " [ 0.9101553   0.6843516  -0.20752335]]\n",
      "168 0.57574743 [[-0.32348463  0.48276004  1.2427803 ]\n",
      " [-0.41955426 -0.60238695 -0.6469373 ]\n",
      " [ 0.9113534   0.68418545 -0.20855528]]\n",
      "169 0.5751227 [[-0.32735607  0.4828154   1.2465963 ]\n",
      " [-0.41923788 -0.6020691  -0.64757156]\n",
      " [ 0.912554    0.6840197  -0.20959014]]\n",
      "170 0.574501 [[-0.33121994  0.48287472  1.2504009 ]\n",
      " [-0.41892704 -0.60175365 -0.6481978 ]\n",
      " [ 0.91375697  0.6838544  -0.2106278 ]]\n",
      "171 0.57388216 [[-0.3350763   0.4829379   1.2541941 ]\n",
      " [-0.41862166 -0.60144067 -0.6488162 ]\n",
      " [ 0.9149622   0.6836896  -0.21166816]]\n",
      "172 0.57326627 [[-0.3389252   0.48300493  1.257976  ]\n",
      " [-0.41832152 -0.6011302  -0.6494269 ]\n",
      " [ 0.9161696   0.68352515 -0.21271114]]\n",
      "173 0.5726533 [[-0.34276673  0.48307577  1.2617468 ]\n",
      " [-0.41802666 -0.60082203 -0.6500299 ]\n",
      " [ 0.9173791   0.6833612  -0.21375665]]\n",
      "174 0.57204306 [[-0.34660092  0.4831504   1.2655063 ]\n",
      " [-0.41773686 -0.60051626 -0.6506254 ]\n",
      " [ 0.9185906   0.68319756 -0.21480459]]\n",
      "175 0.5714357 [[-0.3504278   0.48322877  1.2692548 ]\n",
      " [-0.4174521  -0.6002129  -0.6512136 ]\n",
      " [ 0.9198041   0.6830343  -0.21585485]]\n",
      "176 0.57083106 [[-0.35424748  0.48331088  1.2729924 ]\n",
      " [-0.4171723  -0.5999117  -0.65179455]\n",
      " [ 0.92101943  0.68287146 -0.21690738]]\n",
      "177 0.57022935 [[-0.35805997  0.48339665  1.2767191 ]\n",
      " [-0.41689727 -0.5996129  -0.65236837]\n",
      " [ 0.9222367   0.68270886 -0.21796207]]\n",
      "178 0.56963027 [[-0.36186537  0.4834861   1.2804351 ]\n",
      " [-0.4166271  -0.5993162  -0.6529352 ]\n",
      " [ 0.92345554  0.6825468  -0.21901885]]\n",
      "179 0.56903374 [[-0.36566365  0.4835791   1.2841403 ]\n",
      " [-0.41636145 -0.5990219  -0.6534952 ]\n",
      " [ 0.92467624  0.6823848  -0.2200776 ]]\n",
      "180 0.5684401 [[-0.36945495  0.48367575  1.287835  ]\n",
      " [-0.41610056 -0.5987296  -0.65404844]\n",
      " [ 0.9258984   0.6822233  -0.2211383 ]]\n",
      "181 0.56784904 [[-0.37323925  0.4837759   1.2915192 ]\n",
      " [-0.415844   -0.59843963 -0.654595  ]\n",
      " [ 0.92712224  0.682062   -0.22220083]]\n",
      "182 0.56726056 [[-0.37701666  0.48387963  1.2951928 ]\n",
      " [-0.41559196 -0.5981516  -0.65513504]\n",
      " [ 0.92834747  0.68190104 -0.22326511]]\n",
      "183 0.5666748 [[-0.3807872   0.4839868   1.2988561 ]\n",
      " [-0.41534412 -0.5978658  -0.6556686 ]\n",
      " [ 0.92957425  0.6817402  -0.2243311 ]]\n",
      "184 0.5660915 [[-0.38455093  0.48409745  1.3025092 ]\n",
      " [-0.4151007  -0.597582   -0.6561959 ]\n",
      " [ 0.9308022   0.6815798  -0.22539869]]\n",
      "185 0.56551075 [[-0.38830787  0.48421147  1.3061521 ]\n",
      " [-0.41486126 -0.59730035 -0.65671694]\n",
      " [ 0.9320317   0.6814195  -0.2264678 ]]\n",
      "186 0.56493247 [[-0.3920581   0.48432893  1.3097849 ]\n",
      " [-0.41462612 -0.59702057 -0.65723187]\n",
      " [ 0.9332622   0.6812595  -0.2275384 ]]\n",
      "187 0.5643568 [[-0.39580163  0.4844497   1.3134077 ]\n",
      " [-0.41439486 -0.5967429  -0.6577408 ]\n",
      " [ 0.93449414  0.68109965 -0.22861043]]\n",
      "188 0.5637834 [[-0.39953855  0.48457387  1.3170204 ]\n",
      " [-0.4141677  -0.5964671  -0.6582438 ]\n",
      " [ 0.935727    0.68094015 -0.22968379]]\n",
      "189 0.56321275 [[-0.40326884  0.4847013   1.3206233 ]\n",
      " [-0.4139442  -0.5961934  -0.658741  ]\n",
      " [ 0.9369612   0.6807806  -0.23075843]]\n",
      "190 0.56264424 [[-0.40699264  0.48483205  1.3242164 ]\n",
      " [-0.41372478 -0.59592134 -0.65923244]\n",
      " [ 0.9381962   0.68062145 -0.23183429]]\n",
      "191 0.56207824 [[-0.41070992  0.48496598  1.3277997 ]\n",
      " [-0.4135089  -0.5956514  -0.6597183 ]\n",
      " [ 0.9394324   0.68046224 -0.23291129]]\n",
      "192 0.5615146 [[-0.41442078  0.48510316  1.3313733 ]\n",
      " [-0.41329688 -0.5953831  -0.66019857]\n",
      " [ 0.9406693   0.6803034  -0.23398939]]\n",
      "193 0.5609534 [[-0.4181252   0.4852435   1.3349375 ]\n",
      " [-0.4130883  -0.59511685 -0.6606734 ]\n",
      " [ 0.9419073   0.68014455 -0.2350685 ]]\n",
      "194 0.5603945 [[-0.4218233   0.48538703  1.338492  ]\n",
      " [-0.4128834  -0.59485227 -0.6611428 ]\n",
      " [ 0.943146    0.67998594 -0.23614861]]\n",
      "195 0.55983776 [[-0.42551503  0.48553365  1.3420372 ]\n",
      " [-0.41268188 -0.5945896  -0.661607  ]\n",
      " [ 0.9443856   0.67982733 -0.23722963]]\n",
      "196 0.5592835 [[-0.4292005   0.48568338  1.345573  ]\n",
      " [-0.41248387 -0.5943286  -0.66206604]\n",
      " [ 0.94562584  0.67966896 -0.23831153]]\n",
      "197 0.5587314 [[-0.43287972  0.48583618  1.3490994 ]\n",
      " [-0.41228917 -0.5940694  -0.66251993]\n",
      " [ 0.94686687  0.6795106  -0.23939423]]\n",
      "198 0.5581815 [[-0.43655276  0.485992    1.3526165 ]\n",
      " [-0.4120978  -0.5938119  -0.66296875]\n",
      " [ 0.94810855  0.6793524  -0.24047773]]\n",
      "199 0.55763394 [[-0.44021964  0.48615086  1.3561245 ]\n",
      " [-0.41190967 -0.59355617 -0.66341263]\n",
      " [ 0.9493509   0.6791943  -0.24156193]]\n",
      "200 0.5570884 [[-0.4438804   0.4863127   1.3596234 ]\n",
      " [-0.41172478 -0.5933021  -0.6638517 ]\n",
      " [ 0.95059377  0.67903626 -0.2426468 ]]\n",
      "Prediction: [2 2 2]\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "x_data = [[1, 2, 1],\n",
    "          [1, 3, 2],\n",
    "          [1, 3, 4],\n",
    "          [1, 5, 5],\n",
    "          [1, 7, 5],\n",
    "          [1, 2, 5],\n",
    "          [1, 6, 6],\n",
    "          [1, 7, 7]]\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]\n",
    "\n",
    "# Evaluation our model using this test dataset\n",
    "x_test = [[2, 1, 1],\n",
    "          [3, 1, 2],\n",
    "          [3, 3, 4]]\n",
    "y_test = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1]]\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 3]))\n",
    "b = tf.Variable(tf.random_normal([3]))\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "# Try to change learning_rate to small numbers\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Correct prediction Test model\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(201):\n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], feed_dict={X: x_data, Y: y_data})\n",
    "        print(step, cost_val, W_val)\n",
    "\n",
    "    # predict\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X: x_test}))\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy: \", sess.run(accuracy, feed_dict={X: x_test, Y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21aaf2ae-77f8-4c12-8648-11f013a7ea4c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Cost:  468727820000.0 \n",
      "Prediction:\n",
      " [[483421.66]\n",
      " [973444.06]\n",
      " [765719.4 ]\n",
      " [536688.44]\n",
      " [632562.25]\n",
      " [637885.1 ]\n",
      " [584626.25]\n",
      " [744408.4 ]]\n",
      "1 Cost:  5.149822e+26 \n",
      "Prediction:\n",
      " [[-1.6007644e+13]\n",
      " [-3.2225028e+13]\n",
      " [-2.5350266e+13]\n",
      " [-1.7770402e+13]\n",
      " [-2.0943370e+13]\n",
      " [-2.1119646e+13]\n",
      " [-1.9356887e+13]\n",
      " [-2.4645164e+13]]\n",
      "2 Cost:  inf \n",
      "Prediction:\n",
      " [[5.3059493e+20]\n",
      " [1.0681420e+21]\n",
      " [8.4026881e+20]\n",
      " [5.8902393e+20]\n",
      " [6.9419618e+20]\n",
      " [7.0003903e+20]\n",
      " [6.4161004e+20]\n",
      " [8.1689710e+20]]\n",
      "3 Cost:  inf \n",
      "Prediction:\n",
      " [[-1.7587284e+28]\n",
      " [-3.5405008e+28]\n",
      " [-2.7851842e+28]\n",
      " [-1.9523994e+28]\n",
      " [-2.3010068e+28]\n",
      " [-2.3203740e+28]\n",
      " [-2.1267031e+28]\n",
      " [-2.7077157e+28]]\n",
      "4 Cost:  inf \n",
      "Prediction:\n",
      " [[5.8295432e+35]\n",
      " [1.1735468e+36]\n",
      " [9.2318691e+35]\n",
      " [6.4714914e+35]\n",
      " [7.6269981e+35]\n",
      " [7.6911927e+35]\n",
      " [7.0492449e+35]\n",
      " [8.9750898e+35]]\n",
      "5 Cost:  inf \n",
      "Prediction:\n",
      " [[-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]\n",
      " [-inf]]\n",
      "6 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "7 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "8 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "9 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "10 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "11 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "12 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "13 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "14 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "15 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "16 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "17 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "18 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "19 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "20 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "21 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "22 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "23 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "24 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "25 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "26 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "27 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "28 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "29 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "30 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "31 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "32 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "33 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "34 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "35 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "36 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "37 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "38 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "39 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "40 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "41 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "42 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "43 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "44 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "45 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "46 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "47 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "48 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "49 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "50 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "51 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "52 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "53 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "54 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "55 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "56 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "57 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "58 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "59 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "60 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "61 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "62 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "63 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "64 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "65 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "66 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "67 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "68 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "69 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "70 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "71 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "72 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "73 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "74 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "75 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "76 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "77 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "78 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "79 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "80 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "81 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "82 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "83 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "84 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "85 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "86 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "87 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "88 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "89 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "90 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "91 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "92 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "93 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "94 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "95 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "96 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "97 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "98 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "99 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n",
      "100 Cost:  nan \n",
      "Prediction:\n",
      " [[nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]\n",
      " [nan]]\n"
     ]
    }
   ],
   "source": [
    "xy = np.array([[828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "               [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "               [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "               [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "               [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "               [819, 823, 1198100, 816, 820.450012],\n",
    "               [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "               [809.51001, 816.659973, 1398100, 804.539978, 809.559998]])\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(101):\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4903aeb-511a-480c-94bd-ff9d25924d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
      " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
      " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
      " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
      " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
      " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
      " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
      " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
      "0 Cost:  1.1256323 \n",
      "Prediction:\n",
      " [[-0.7942449 ]\n",
      " [-0.98297   ]\n",
      " [-0.4594388 ]\n",
      " [ 0.14247596]\n",
      " [-0.22507024]\n",
      " [-0.16875577]\n",
      " [ 0.46886328]\n",
      " [ 0.43321937]]\n",
      "1 Cost:  1.1255717 \n",
      "Prediction:\n",
      " [[-0.7941978 ]\n",
      " [-0.982926  ]\n",
      " [-0.45940268]\n",
      " [ 0.14250308]\n",
      " [-0.22503722]\n",
      " [-0.16872412]\n",
      " [ 0.46888247]\n",
      " [ 0.43323776]]\n",
      "2 Cost:  1.1255114 \n",
      "Prediction:\n",
      " [[-0.7941507 ]\n",
      " [-0.9828819 ]\n",
      " [-0.45936668]\n",
      " [ 0.1425302 ]\n",
      " [-0.22500432]\n",
      " [-0.16869253]\n",
      " [ 0.46890166]\n",
      " [ 0.43325615]]\n",
      "3 Cost:  1.1254508 \n",
      "Prediction:\n",
      " [[-0.7941035 ]\n",
      " [-0.9828379 ]\n",
      " [-0.45933044]\n",
      " [ 0.14255726]\n",
      " [-0.22497141]\n",
      " [-0.16866088]\n",
      " [ 0.46892086]\n",
      " [ 0.4332745 ]]\n",
      "4 Cost:  1.1253903 \n",
      "Prediction:\n",
      " [[-0.79405653]\n",
      " [-0.9827937 ]\n",
      " [-0.45929444]\n",
      " [ 0.14258438]\n",
      " [-0.22493851]\n",
      " [-0.16862929]\n",
      " [ 0.46894002]\n",
      " [ 0.4332929 ]]\n",
      "5 Cost:  1.1253297 \n",
      "Prediction:\n",
      " [[-0.7940093 ]\n",
      " [-0.9827496 ]\n",
      " [-0.45925832]\n",
      " [ 0.14261144]\n",
      " [-0.22490561]\n",
      " [-0.16859764]\n",
      " [ 0.4689592 ]\n",
      " [ 0.43331128]]\n",
      "6 Cost:  1.1252692 \n",
      "Prediction:\n",
      " [[-0.7939621 ]\n",
      " [-0.9827056 ]\n",
      " [-0.4592222 ]\n",
      " [ 0.14263856]\n",
      " [-0.22487259]\n",
      " [-0.16856599]\n",
      " [ 0.4689784 ]\n",
      " [ 0.43332967]]\n",
      "7 Cost:  1.1252086 \n",
      "Prediction:\n",
      " [[-0.79391503]\n",
      " [-0.98266137]\n",
      " [-0.45918608]\n",
      " [ 0.14266562]\n",
      " [-0.2248398 ]\n",
      " [-0.16853446]\n",
      " [ 0.4689976 ]\n",
      " [ 0.43334806]]\n",
      "8 Cost:  1.125148 \n",
      "Prediction:\n",
      " [[-0.79386795]\n",
      " [-0.9826175 ]\n",
      " [-0.45915008]\n",
      " [ 0.14269274]\n",
      " [-0.22480679]\n",
      " [-0.16850281]\n",
      " [ 0.4690168 ]\n",
      " [ 0.43336645]]\n",
      "9 Cost:  1.1250875 \n",
      "Prediction:\n",
      " [[-0.79382086]\n",
      " [-0.9825733 ]\n",
      " [-0.45911396]\n",
      " [ 0.14271986]\n",
      " [-0.22477388]\n",
      " [-0.16847122]\n",
      " [ 0.46903595]\n",
      " [ 0.4333848 ]]\n",
      "10 Cost:  1.1250271 \n",
      "Prediction:\n",
      " [[-0.7937738 ]\n",
      " [-0.9825293 ]\n",
      " [-0.45907784]\n",
      " [ 0.14274693]\n",
      " [-0.22474098]\n",
      " [-0.16843963]\n",
      " [ 0.46905515]\n",
      " [ 0.4334032 ]]\n",
      "11 Cost:  1.1249664 \n",
      "Prediction:\n",
      " [[-0.79372656]\n",
      " [-0.9824852 ]\n",
      " [-0.4590417 ]\n",
      " [ 0.14277405]\n",
      " [-0.22470796]\n",
      " [-0.16840804]\n",
      " [ 0.46907434]\n",
      " [ 0.4334216 ]]\n",
      "12 Cost:  1.1249061 \n",
      "Prediction:\n",
      " [[-0.7936796 ]\n",
      " [-0.9824412 ]\n",
      " [-0.4590056 ]\n",
      " [ 0.14280105]\n",
      " [-0.22467506]\n",
      " [-0.16837633]\n",
      " [ 0.4690935 ]\n",
      " [ 0.43343997]]\n",
      "13 Cost:  1.1248455 \n",
      "Prediction:\n",
      " [[-0.7936324 ]\n",
      " [-0.98239696]\n",
      " [-0.45896947]\n",
      " [ 0.14282823]\n",
      " [-0.22464216]\n",
      " [-0.16834486]\n",
      " [ 0.4691127 ]\n",
      " [ 0.43345836]]\n",
      "14 Cost:  1.124785 \n",
      "Prediction:\n",
      " [[-0.7935852 ]\n",
      " [-0.982353  ]\n",
      " [-0.45893347]\n",
      " [ 0.14285529]\n",
      " [-0.22460926]\n",
      " [-0.1683132 ]\n",
      " [ 0.4691319 ]\n",
      " [ 0.43347675]]\n",
      "15 Cost:  1.1247244 \n",
      "Prediction:\n",
      " [[-0.7935381 ]\n",
      " [-0.98230886]\n",
      " [-0.45889723]\n",
      " [ 0.14288235]\n",
      " [-0.22457635]\n",
      " [-0.16828156]\n",
      " [ 0.46915108]\n",
      " [ 0.4334951 ]]\n",
      "16 Cost:  1.124664 \n",
      "Prediction:\n",
      " [[-0.793491  ]\n",
      " [-0.9822649 ]\n",
      " [-0.45886123]\n",
      " [ 0.14290947]\n",
      " [-0.22454345]\n",
      " [-0.16824996]\n",
      " [ 0.46917027]\n",
      " [ 0.4335135 ]]\n",
      "17 Cost:  1.1246035 \n",
      "Prediction:\n",
      " [[-0.7934439 ]\n",
      " [-0.98222077]\n",
      " [-0.4588251 ]\n",
      " [ 0.14293653]\n",
      " [-0.22451043]\n",
      " [-0.16821837]\n",
      " [ 0.46918947]\n",
      " [ 0.43353188]]\n",
      "18 Cost:  1.124543 \n",
      "Prediction:\n",
      " [[-0.79339683]\n",
      " [-0.98217654]\n",
      " [-0.4587891 ]\n",
      " [ 0.14296365]\n",
      " [-0.22447753]\n",
      " [-0.16818672]\n",
      " [ 0.46920866]\n",
      " [ 0.43355027]]\n",
      "19 Cost:  1.1244824 \n",
      "Prediction:\n",
      " [[-0.7933496 ]\n",
      " [-0.98213255]\n",
      " [-0.458753  ]\n",
      " [ 0.14299071]\n",
      " [-0.22444463]\n",
      " [-0.16815513]\n",
      " [ 0.46922785]\n",
      " [ 0.43356866]]\n",
      "20 Cost:  1.1244218 \n",
      "Prediction:\n",
      " [[-0.79330266]\n",
      " [-0.98208845]\n",
      " [-0.45871687]\n",
      " [ 0.14301783]\n",
      " [-0.2244116 ]\n",
      " [-0.16812354]\n",
      " [ 0.469247  ]\n",
      " [ 0.433587  ]]\n",
      "21 Cost:  1.1243613 \n",
      "Prediction:\n",
      " [[-0.79325545]\n",
      " [-0.98204434]\n",
      " [-0.45868075]\n",
      " [ 0.14304495]\n",
      " [-0.22437882]\n",
      " [-0.1680919 ]\n",
      " [ 0.4692662 ]\n",
      " [ 0.4336054 ]]\n",
      "22 Cost:  1.1243007 \n",
      "Prediction:\n",
      " [[-0.79320824]\n",
      " [-0.98200023]\n",
      " [-0.45864463]\n",
      " [ 0.14307201]\n",
      " [-0.2243458 ]\n",
      " [-0.16806024]\n",
      " [ 0.4692854 ]\n",
      " [ 0.4336238 ]]\n",
      "23 Cost:  1.1242404 \n",
      "Prediction:\n",
      " [[-0.79316115]\n",
      " [-0.98195624]\n",
      " [-0.45860863]\n",
      " [ 0.14309907]\n",
      " [-0.2243129 ]\n",
      " [-0.16802871]\n",
      " [ 0.4693046 ]\n",
      " [ 0.43364218]]\n",
      "24 Cost:  1.1241798 \n",
      "Prediction:\n",
      " [[-0.79311407]\n",
      " [-0.98191214]\n",
      " [-0.4585724 ]\n",
      " [ 0.14312619]\n",
      " [-0.22428   ]\n",
      " [-0.16799712]\n",
      " [ 0.46932378]\n",
      " [ 0.43366057]]\n",
      "25 Cost:  1.1241194 \n",
      "Prediction:\n",
      " [[-0.793067  ]\n",
      " [-0.981868  ]\n",
      " [-0.4585364 ]\n",
      " [ 0.14315331]\n",
      " [-0.2242471 ]\n",
      " [-0.16796553]\n",
      " [ 0.46934295]\n",
      " [ 0.43367895]]\n",
      "26 Cost:  1.124059 \n",
      "Prediction:\n",
      " [[-0.7930199 ]\n",
      " [-0.98182404]\n",
      " [-0.45850027]\n",
      " [ 0.14318037]\n",
      " [-0.22421408]\n",
      " [-0.16793394]\n",
      " [ 0.46936214]\n",
      " [ 0.4336973 ]]\n",
      "27 Cost:  1.1239984 \n",
      "Prediction:\n",
      " [[-0.7929727 ]\n",
      " [-0.98177993]\n",
      " [-0.45846426]\n",
      " [ 0.14320743]\n",
      " [-0.2241813 ]\n",
      " [-0.16790223]\n",
      " [ 0.46938133]\n",
      " [ 0.4337157 ]]\n",
      "28 Cost:  1.1239381 \n",
      "Prediction:\n",
      " [[-0.7929257 ]\n",
      " [-0.9817358 ]\n",
      " [-0.45842814]\n",
      " [ 0.14323449]\n",
      " [-0.22414827]\n",
      " [-0.16787064]\n",
      " [ 0.46940053]\n",
      " [ 0.4337341 ]]\n",
      "29 Cost:  1.1238775 \n",
      "Prediction:\n",
      " [[-0.7928785 ]\n",
      " [-0.9816917 ]\n",
      " [-0.45839202]\n",
      " [ 0.14326161]\n",
      " [-0.22411537]\n",
      " [-0.16783911]\n",
      " [ 0.46941972]\n",
      " [ 0.43375248]]\n",
      "30 Cost:  1.123817 \n",
      "Prediction:\n",
      " [[-0.7928313 ]\n",
      " [-0.9816476 ]\n",
      " [-0.45835578]\n",
      " [ 0.14328873]\n",
      " [-0.22408247]\n",
      " [-0.16780746]\n",
      " [ 0.4694389 ]\n",
      " [ 0.43377087]]\n",
      "31 Cost:  1.1237564 \n",
      "Prediction:\n",
      " [[-0.7927842 ]\n",
      " [-0.9816036 ]\n",
      " [-0.45831978]\n",
      " [ 0.14331579]\n",
      " [-0.22404945]\n",
      " [-0.16777587]\n",
      " [ 0.4694581 ]\n",
      " [ 0.43378925]]\n",
      "32 Cost:  1.1236959 \n",
      "Prediction:\n",
      " [[-0.7927371 ]\n",
      " [-0.9815594 ]\n",
      " [-0.45828366]\n",
      " [ 0.14334291]\n",
      " [-0.22401655]\n",
      " [-0.16774428]\n",
      " [ 0.46947727]\n",
      " [ 0.4338076 ]]\n",
      "33 Cost:  1.1236355 \n",
      "Prediction:\n",
      " [[-0.79269004]\n",
      " [-0.9815155 ]\n",
      " [-0.45824754]\n",
      " [ 0.14336997]\n",
      " [-0.22398365]\n",
      " [-0.16771263]\n",
      " [ 0.46949646]\n",
      " [ 0.433826  ]]\n",
      "34 Cost:  1.123575 \n",
      "Prediction:\n",
      " [[-0.79264295]\n",
      " [-0.9814713 ]\n",
      " [-0.45821142]\n",
      " [ 0.1433971 ]\n",
      " [-0.22395074]\n",
      " [-0.16768098]\n",
      " [ 0.46951565]\n",
      " [ 0.43384442]]\n",
      "35 Cost:  1.1235147 \n",
      "Prediction:\n",
      " [[-0.79259574]\n",
      " [-0.9814273 ]\n",
      " [-0.45817542]\n",
      " [ 0.14342415]\n",
      " [-0.22391784]\n",
      " [-0.16764945]\n",
      " [ 0.4695348 ]\n",
      " [ 0.43386278]]\n",
      "36 Cost:  1.1234542 \n",
      "Prediction:\n",
      " [[-0.7925488 ]\n",
      " [-0.9813832 ]\n",
      " [-0.4581393 ]\n",
      " [ 0.14345127]\n",
      " [-0.22388494]\n",
      " [-0.1676178 ]\n",
      " [ 0.469554  ]\n",
      " [ 0.43388116]]\n",
      "37 Cost:  1.1233938 \n",
      "Prediction:\n",
      " [[-0.79250157]\n",
      " [-0.9813392 ]\n",
      " [-0.4581033 ]\n",
      " [ 0.1434784 ]\n",
      " [-0.22385192]\n",
      " [-0.1675862 ]\n",
      " [ 0.4695732 ]\n",
      " [ 0.43389955]]\n",
      "38 Cost:  1.1233332 \n",
      "Prediction:\n",
      " [[-0.79245436]\n",
      " [-0.981295  ]\n",
      " [-0.45806706]\n",
      " [ 0.14350545]\n",
      " [-0.22381902]\n",
      " [-0.16755462]\n",
      " [ 0.4695924 ]\n",
      " [ 0.4339179 ]]\n",
      "39 Cost:  1.1232727 \n",
      "Prediction:\n",
      " [[-0.7924073 ]\n",
      " [-0.9812509 ]\n",
      " [-0.45803106]\n",
      " [ 0.14353251]\n",
      " [-0.22378612]\n",
      " [-0.16752303]\n",
      " [ 0.4696116 ]\n",
      " [ 0.4339363 ]]\n",
      "40 Cost:  1.1232123 \n",
      "Prediction:\n",
      " [[-0.7923602 ]\n",
      " [-0.9812069 ]\n",
      " [-0.45799494]\n",
      " [ 0.14355958]\n",
      " [-0.22375321]\n",
      " [-0.16749132]\n",
      " [ 0.46963078]\n",
      " [ 0.43395472]]\n",
      "41 Cost:  1.1231518 \n",
      "Prediction:\n",
      " [[-0.7923131 ]\n",
      " [-0.98116267]\n",
      " [-0.45795882]\n",
      " [ 0.1435867 ]\n",
      " [-0.22372031]\n",
      " [-0.16745985]\n",
      " [ 0.46964997]\n",
      " [ 0.43397307]]\n",
      "42 Cost:  1.1230915 \n",
      "Prediction:\n",
      " [[-0.792266  ]\n",
      " [-0.9811188 ]\n",
      " [-0.4579227 ]\n",
      " [ 0.14361382]\n",
      " [-0.22368741]\n",
      " [-0.1674282 ]\n",
      " [ 0.46966916]\n",
      " [ 0.43399146]]\n",
      "43 Cost:  1.1230309 \n",
      "Prediction:\n",
      " [[-0.7922188 ]\n",
      " [-0.9810746 ]\n",
      " [-0.4578867 ]\n",
      " [ 0.14364088]\n",
      " [-0.22365439]\n",
      " [-0.1673966 ]\n",
      " [ 0.46968833]\n",
      " [ 0.43400985]]\n",
      "44 Cost:  1.1229706 \n",
      "Prediction:\n",
      " [[-0.79217184]\n",
      " [-0.9810306 ]\n",
      " [-0.45785058]\n",
      " [ 0.143668  ]\n",
      " [-0.22362149]\n",
      " [-0.16736495]\n",
      " [ 0.46970752]\n",
      " [ 0.4340282 ]]\n",
      "45 Cost:  1.12291 \n",
      "Prediction:\n",
      " [[-0.7921246 ]\n",
      " [-0.9809865 ]\n",
      " [-0.45781446]\n",
      " [ 0.14369506]\n",
      " [-0.22358859]\n",
      " [-0.16733336]\n",
      " [ 0.4697267 ]\n",
      " [ 0.4340466 ]]\n",
      "46 Cost:  1.1228496 \n",
      "Prediction:\n",
      " [[-0.7920774 ]\n",
      " [-0.98094237]\n",
      " [-0.45777833]\n",
      " [ 0.14372212]\n",
      " [-0.22355568]\n",
      " [-0.16730171]\n",
      " [ 0.4697459 ]\n",
      " [ 0.43406498]]\n",
      "47 Cost:  1.1227891 \n",
      "Prediction:\n",
      " [[-0.79203033]\n",
      " [-0.98089826]\n",
      " [-0.4577422 ]\n",
      " [ 0.14374924]\n",
      " [-0.22352278]\n",
      " [-0.16727012]\n",
      " [ 0.4697651 ]\n",
      " [ 0.43408337]]\n",
      "48 Cost:  1.1227287 \n",
      "Prediction:\n",
      " [[-0.79198325]\n",
      " [-0.98085415]\n",
      " [-0.4577061 ]\n",
      " [ 0.14377636]\n",
      " [-0.22348988]\n",
      " [-0.16723853]\n",
      " [ 0.46978426]\n",
      " [ 0.43410176]]\n",
      "49 Cost:  1.1226683 \n",
      "Prediction:\n",
      " [[-0.79193616]\n",
      " [-0.98081017]\n",
      " [-0.4576701 ]\n",
      " [ 0.14380342]\n",
      " [-0.22345686]\n",
      " [-0.16720694]\n",
      " [ 0.46980345]\n",
      " [ 0.43412012]]\n",
      "50 Cost:  1.1226082 \n",
      "Prediction:\n",
      " [[-0.79188913]\n",
      " [-0.98076636]\n",
      " [-0.45763415]\n",
      " [ 0.14383042]\n",
      " [-0.22342414]\n",
      " [-0.16717547]\n",
      " [ 0.46982256]\n",
      " [ 0.4341384 ]]\n",
      "51 Cost:  1.1225476 \n",
      "Prediction:\n",
      " [[-0.791842  ]\n",
      " [-0.9807223 ]\n",
      " [-0.4575981 ]\n",
      " [ 0.14385742]\n",
      " [-0.22339118]\n",
      " [-0.16714394]\n",
      " [ 0.46984166]\n",
      " [ 0.4341567 ]]\n",
      "52 Cost:  1.1224875 \n",
      "Prediction:\n",
      " [[-0.7917951 ]\n",
      " [-0.9806784 ]\n",
      " [-0.45756215]\n",
      " [ 0.14388448]\n",
      " [-0.22335845]\n",
      " [-0.16711241]\n",
      " [ 0.4698608 ]\n",
      " [ 0.43417495]]\n",
      "53 Cost:  1.1224272 \n",
      "Prediction:\n",
      " [[-0.79174805]\n",
      " [-0.98063445]\n",
      " [-0.4575261 ]\n",
      " [ 0.14391142]\n",
      " [-0.22332561]\n",
      " [-0.16708082]\n",
      " [ 0.46987987]\n",
      " [ 0.43419328]]\n",
      "54 Cost:  1.122367 \n",
      "Prediction:\n",
      " [[-0.791701  ]\n",
      " [-0.9805905 ]\n",
      " [-0.45749015]\n",
      " [ 0.14393848]\n",
      " [-0.22329277]\n",
      " [-0.16704941]\n",
      " [ 0.46989897]\n",
      " [ 0.43421158]]\n",
      "55 Cost:  1.1223066 \n",
      "Prediction:\n",
      " [[-0.7916539 ]\n",
      " [-0.9805465 ]\n",
      " [-0.4574541 ]\n",
      " [ 0.14396548]\n",
      " [-0.22325993]\n",
      " [-0.16701788]\n",
      " [ 0.4699181 ]\n",
      " [ 0.43422985]]\n",
      "56 Cost:  1.1222465 \n",
      "Prediction:\n",
      " [[-0.79160684]\n",
      " [-0.98050267]\n",
      " [-0.45741814]\n",
      " [ 0.14399248]\n",
      " [-0.22322708]\n",
      " [-0.16698629]\n",
      " [ 0.4699372 ]\n",
      " [ 0.43424815]]\n",
      "57 Cost:  1.1221862 \n",
      "Prediction:\n",
      " [[-0.79155993]\n",
      " [-0.98045886]\n",
      " [-0.4573822 ]\n",
      " [ 0.14401948]\n",
      " [-0.22319424]\n",
      " [-0.16695476]\n",
      " [ 0.4699563 ]\n",
      " [ 0.43426645]]\n",
      "58 Cost:  1.1221259 \n",
      "Prediction:\n",
      " [[-0.7915129 ]\n",
      " [-0.9804147 ]\n",
      " [-0.45734614]\n",
      " [ 0.14404649]\n",
      " [-0.2231614 ]\n",
      " [-0.16692322]\n",
      " [ 0.4699754 ]\n",
      " [ 0.43428472]]\n",
      "59 Cost:  1.1220655 \n",
      "Prediction:\n",
      " [[-0.79146576]\n",
      " [-0.98037076]\n",
      " [-0.4573102 ]\n",
      " [ 0.14407355]\n",
      " [-0.22312856]\n",
      " [-0.16689175]\n",
      " [ 0.46999454]\n",
      " [ 0.43430302]]\n",
      "60 Cost:  1.1220055 \n",
      "Prediction:\n",
      " [[-0.79141885]\n",
      " [-0.98032695]\n",
      " [-0.45727426]\n",
      " [ 0.14410049]\n",
      " [-0.22309583]\n",
      " [-0.16686028]\n",
      " [ 0.47001362]\n",
      " [ 0.4343213 ]]\n",
      "61 Cost:  1.1219451 \n",
      "Prediction:\n",
      " [[-0.7913718 ]\n",
      " [-0.9802829 ]\n",
      " [-0.4572382 ]\n",
      " [ 0.14412749]\n",
      " [-0.22306287]\n",
      " [-0.16682881]\n",
      " [ 0.47003275]\n",
      " [ 0.43433958]]\n",
      "62 Cost:  1.121885 \n",
      "Prediction:\n",
      " [[-0.7913248 ]\n",
      " [-0.980239  ]\n",
      " [-0.45720237]\n",
      " [ 0.14415449]\n",
      " [-0.22303003]\n",
      " [-0.16679722]\n",
      " [ 0.47005185]\n",
      " [ 0.43435788]]\n",
      "63 Cost:  1.1218247 \n",
      "Prediction:\n",
      " [[-0.7912779 ]\n",
      " [-0.98019505]\n",
      " [-0.4571663 ]\n",
      " [ 0.14418155]\n",
      " [-0.22299719]\n",
      " [-0.16676581]\n",
      " [ 0.47007096]\n",
      " [ 0.4343762 ]]\n",
      "64 Cost:  1.1217644 \n",
      "Prediction:\n",
      " [[-0.79123074]\n",
      " [-0.98015124]\n",
      " [-0.45713037]\n",
      " [ 0.14420855]\n",
      " [-0.22296447]\n",
      " [-0.16673422]\n",
      " [ 0.47009006]\n",
      " [ 0.43439448]]\n",
      "65 Cost:  1.1217042 \n",
      "Prediction:\n",
      " [[-0.7911838 ]\n",
      " [-0.9801072 ]\n",
      " [-0.45709443]\n",
      " [ 0.14423549]\n",
      " [-0.22293162]\n",
      " [-0.16670275]\n",
      " [ 0.47010916]\n",
      " [ 0.43441278]]\n",
      "66 Cost:  1.121644 \n",
      "Prediction:\n",
      " [[-0.7911368 ]\n",
      " [-0.98006326]\n",
      " [-0.45705837]\n",
      " [ 0.1442625 ]\n",
      " [-0.2228989 ]\n",
      " [-0.16667122]\n",
      " [ 0.4701283 ]\n",
      " [ 0.43443105]]\n",
      "67 Cost:  1.1215838 \n",
      "Prediction:\n",
      " [[-0.7910898 ]\n",
      " [-0.98001945]\n",
      " [-0.45702243]\n",
      " [ 0.1442895 ]\n",
      " [-0.22286606]\n",
      " [-0.16663975]\n",
      " [ 0.4701474 ]\n",
      " [ 0.43444934]]\n",
      "68 Cost:  1.1215236 \n",
      "Prediction:\n",
      " [[-0.79104275]\n",
      " [-0.9799755 ]\n",
      " [-0.4569865 ]\n",
      " [ 0.1443165 ]\n",
      " [-0.22283322]\n",
      " [-0.16660821]\n",
      " [ 0.4701665 ]\n",
      " [ 0.4344676 ]]\n",
      "69 Cost:  1.1214635 \n",
      "Prediction:\n",
      " [[-0.79099584]\n",
      " [-0.9799316 ]\n",
      " [-0.45695055]\n",
      " [ 0.14434355]\n",
      " [-0.22280037]\n",
      " [-0.16657668]\n",
      " [ 0.47018564]\n",
      " [ 0.4344859 ]]\n",
      "70 Cost:  1.1214032 \n",
      "Prediction:\n",
      " [[-0.7909488 ]\n",
      " [-0.97988755]\n",
      " [-0.45691448]\n",
      " [ 0.14437056]\n",
      " [-0.22276753]\n",
      " [-0.16654521]\n",
      " [ 0.47020474]\n",
      " [ 0.4345042 ]]\n",
      "71 Cost:  1.1213431 \n",
      "Prediction:\n",
      " [[-0.7909019 ]\n",
      " [-0.97984374]\n",
      " [-0.45687866]\n",
      " [ 0.1443975 ]\n",
      " [-0.22273481]\n",
      " [-0.16651374]\n",
      " [ 0.47022384]\n",
      " [ 0.43452248]]\n",
      "72 Cost:  1.1212827 \n",
      "Prediction:\n",
      " [[-0.79085475]\n",
      " [-0.9797998 ]\n",
      " [-0.4568426 ]\n",
      " [ 0.14442456]\n",
      " [-0.22270185]\n",
      " [-0.16648215]\n",
      " [ 0.47024295]\n",
      " [ 0.4345408 ]]\n",
      "73 Cost:  1.1212225 \n",
      "Prediction:\n",
      " [[-0.79080784]\n",
      " [-0.9797559 ]\n",
      " [-0.45680654]\n",
      " [ 0.1444515 ]\n",
      " [-0.22266912]\n",
      " [-0.16645074]\n",
      " [ 0.47026205]\n",
      " [ 0.43455908]]\n",
      "74 Cost:  1.1211624 \n",
      "Prediction:\n",
      " [[-0.7907608 ]\n",
      " [-0.97971195]\n",
      " [-0.4567706 ]\n",
      " [ 0.14447856]\n",
      " [-0.22263628]\n",
      " [-0.16641927]\n",
      " [ 0.47028115]\n",
      " [ 0.43457738]]\n",
      "75 Cost:  1.1211022 \n",
      "Prediction:\n",
      " [[-0.7907138 ]\n",
      " [-0.979668  ]\n",
      " [-0.45673466]\n",
      " [ 0.1445055 ]\n",
      " [-0.22260344]\n",
      " [-0.16638774]\n",
      " [ 0.47030026]\n",
      " [ 0.43459564]]\n",
      "76 Cost:  1.121042 \n",
      "Prediction:\n",
      " [[-0.79066676]\n",
      " [-0.9796241 ]\n",
      " [-0.45669872]\n",
      " [ 0.1445325 ]\n",
      " [-0.22257072]\n",
      " [-0.16635627]\n",
      " [ 0.4703194 ]\n",
      " [ 0.43461394]]\n",
      "77 Cost:  1.1209819 \n",
      "Prediction:\n",
      " [[-0.79061985]\n",
      " [-0.9795803 ]\n",
      " [-0.45666277]\n",
      " [ 0.14455956]\n",
      " [-0.22253788]\n",
      " [-0.16632473]\n",
      " [ 0.4703385 ]\n",
      " [ 0.43463224]]\n",
      "78 Cost:  1.1209216 \n",
      "Prediction:\n",
      " [[-0.7905728 ]\n",
      " [-0.97953624]\n",
      " [-0.4566267 ]\n",
      " [ 0.1445865 ]\n",
      " [-0.22250503]\n",
      " [-0.16629314]\n",
      " [ 0.4703576 ]\n",
      " [ 0.4346505 ]]\n",
      "79 Cost:  1.1208615 \n",
      "Prediction:\n",
      " [[-0.7905259 ]\n",
      " [-0.9794923 ]\n",
      " [-0.45659077]\n",
      " [ 0.1446135 ]\n",
      " [-0.22247219]\n",
      " [-0.16626167]\n",
      " [ 0.47037673]\n",
      " [ 0.4346688 ]]\n",
      "80 Cost:  1.1208012 \n",
      "Prediction:\n",
      " [[-0.79047877]\n",
      " [-0.9794485 ]\n",
      " [-0.45655483]\n",
      " [ 0.1446405 ]\n",
      " [-0.22243935]\n",
      " [-0.1662302 ]\n",
      " [ 0.4703958 ]\n",
      " [ 0.43468708]]\n",
      "81 Cost:  1.1207411 \n",
      "Prediction:\n",
      " [[-0.79043186]\n",
      " [-0.97940457]\n",
      " [-0.4565189 ]\n",
      " [ 0.1446675 ]\n",
      " [-0.2224065 ]\n",
      " [-0.16619867]\n",
      " [ 0.4704149 ]\n",
      " [ 0.4347054 ]]\n",
      "82 Cost:  1.120681 \n",
      "Prediction:\n",
      " [[-0.7903848 ]\n",
      " [-0.97936076]\n",
      " [-0.45648283]\n",
      " [ 0.1446945 ]\n",
      " [-0.22237378]\n",
      " [-0.1661672 ]\n",
      " [ 0.47043404]\n",
      " [ 0.4347237 ]]\n",
      "83 Cost:  1.1206207 \n",
      "Prediction:\n",
      " [[-0.7903378 ]\n",
      " [-0.9793166 ]\n",
      " [-0.4564469 ]\n",
      " [ 0.14472151]\n",
      " [-0.22234106]\n",
      " [-0.16613579]\n",
      " [ 0.47045314]\n",
      " [ 0.43474197]]\n",
      "84 Cost:  1.1205605 \n",
      "Prediction:\n",
      " [[-0.7902908 ]\n",
      " [-0.9792728 ]\n",
      " [-0.45641094]\n",
      " [ 0.14474851]\n",
      " [-0.2223081 ]\n",
      " [-0.1661042 ]\n",
      " [ 0.47047225]\n",
      " [ 0.43476027]]\n",
      "85 Cost:  1.1205003 \n",
      "Prediction:\n",
      " [[-0.79024386]\n",
      " [-0.97922885]\n",
      " [-0.45637488]\n",
      " [ 0.14477551]\n",
      " [-0.22227526]\n",
      " [-0.16607267]\n",
      " [ 0.47049135]\n",
      " [ 0.43477854]]\n",
      "86 Cost:  1.1204402 \n",
      "Prediction:\n",
      " [[-0.79019684]\n",
      " [-0.97918504]\n",
      " [-0.45633894]\n",
      " [ 0.14480251]\n",
      " [-0.22224253]\n",
      " [-0.1660412 ]\n",
      " [ 0.47051048]\n",
      " [ 0.43479684]]\n",
      "87 Cost:  1.1203802 \n",
      "Prediction:\n",
      " [[-0.7901499 ]\n",
      " [-0.979141  ]\n",
      " [-0.456303  ]\n",
      " [ 0.14482957]\n",
      " [-0.22220969]\n",
      " [-0.16600966]\n",
      " [ 0.47052956]\n",
      " [ 0.4348151 ]]\n",
      "88 Cost:  1.1203198 \n",
      "Prediction:\n",
      " [[-0.7901028 ]\n",
      " [-0.97909707]\n",
      " [-0.45626706]\n",
      " [ 0.14485651]\n",
      " [-0.22217685]\n",
      " [-0.1659782 ]\n",
      " [ 0.4705487 ]\n",
      " [ 0.4348334 ]]\n",
      "89 Cost:  1.1202598 \n",
      "Prediction:\n",
      " [[-0.7900559 ]\n",
      " [-0.97905314]\n",
      " [-0.45623112]\n",
      " [ 0.14488351]\n",
      " [-0.22214413]\n",
      " [-0.16594672]\n",
      " [ 0.4705678 ]\n",
      " [ 0.4348517 ]]\n",
      "90 Cost:  1.1201996 \n",
      "Prediction:\n",
      " [[-0.79000884]\n",
      " [-0.97900933]\n",
      " [-0.45619506]\n",
      " [ 0.14491051]\n",
      " [-0.22211117]\n",
      " [-0.16591519]\n",
      " [ 0.47058693]\n",
      " [ 0.43487   ]]\n",
      "91 Cost:  1.1201394 \n",
      "Prediction:\n",
      " [[-0.7899618 ]\n",
      " [-0.9789653 ]\n",
      " [-0.4561591 ]\n",
      " [ 0.14493752]\n",
      " [-0.22207844]\n",
      " [-0.16588372]\n",
      " [ 0.47060603]\n",
      " [ 0.4348883 ]]\n",
      "92 Cost:  1.1200793 \n",
      "Prediction:\n",
      " [[-0.7899148 ]\n",
      " [-0.9789215 ]\n",
      " [-0.45612317]\n",
      " [ 0.14496452]\n",
      " [-0.2220456 ]\n",
      " [-0.16585213]\n",
      " [ 0.4706251 ]\n",
      " [ 0.43490657]]\n",
      "93 Cost:  1.1200192 \n",
      "Prediction:\n",
      " [[-0.7898679 ]\n",
      " [-0.9788774 ]\n",
      " [-0.45608723]\n",
      " [ 0.14499152]\n",
      " [-0.22201276]\n",
      " [-0.16582066]\n",
      " [ 0.47064424]\n",
      " [ 0.43492487]]\n",
      "94 Cost:  1.1199591 \n",
      "Prediction:\n",
      " [[-0.78982085]\n",
      " [-0.9788336 ]\n",
      " [-0.4560513 ]\n",
      " [ 0.14501852]\n",
      " [-0.22198004]\n",
      " [-0.16578913]\n",
      " [ 0.47066334]\n",
      " [ 0.43494314]]\n",
      "95 Cost:  1.1198989 \n",
      "Prediction:\n",
      " [[-0.78977394]\n",
      " [-0.9787898 ]\n",
      " [-0.45601523]\n",
      " [ 0.14504552]\n",
      " [-0.2219472 ]\n",
      " [-0.16575766]\n",
      " [ 0.47068244]\n",
      " [ 0.43496144]]\n",
      "96 Cost:  1.1198386 \n",
      "Prediction:\n",
      " [[-0.7897268 ]\n",
      " [-0.97874564]\n",
      " [-0.4559794 ]\n",
      " [ 0.14507252]\n",
      " [-0.22191435]\n",
      " [-0.16572618]\n",
      " [ 0.47070158]\n",
      " [ 0.43497974]]\n",
      "97 Cost:  1.1197785 \n",
      "Prediction:\n",
      " [[-0.7896799 ]\n",
      " [-0.97870183]\n",
      " [-0.45594323]\n",
      " [ 0.14509952]\n",
      " [-0.22188151]\n",
      " [-0.16569471]\n",
      " [ 0.47072068]\n",
      " [ 0.434998  ]]\n",
      "98 Cost:  1.1197183 \n",
      "Prediction:\n",
      " [[-0.78963286]\n",
      " [-0.9786579 ]\n",
      " [-0.4559073 ]\n",
      " [ 0.14512652]\n",
      " [-0.22184867]\n",
      " [-0.16566312]\n",
      " [ 0.47073978]\n",
      " [ 0.4350163 ]]\n",
      "99 Cost:  1.1196582 \n",
      "Prediction:\n",
      " [[-0.7895858 ]\n",
      " [-0.9786141 ]\n",
      " [-0.45587134]\n",
      " [ 0.14515352]\n",
      " [-0.22181582]\n",
      " [-0.16563171]\n",
      " [ 0.4707589 ]\n",
      " [ 0.4350346 ]]\n",
      "100 Cost:  1.1195982 \n",
      "Prediction:\n",
      " [[-0.7895388 ]\n",
      " [-0.97857004]\n",
      " [-0.4558354 ]\n",
      " [ 0.14518058]\n",
      " [-0.2217831 ]\n",
      " [-0.16560018]\n",
      " [ 0.470778  ]\n",
      " [ 0.4350529 ]]\n"
     ]
    }
   ],
   "source": [
    "def min_max_scaler(data):\n",
    "    numerator = data - np.min(data, 0)\n",
    "    denominator = np.max(data, 0) - np.min(data, 0)\n",
    "    # noise term prevents the zero division\n",
    "    return numerator / (denominator + 1e-7)\n",
    "\n",
    "\n",
    "xy = np.array(\n",
    "    [\n",
    "        [828.659973, 833.450012, 908100, 828.349976, 831.659973],\n",
    "        [823.02002, 828.070007, 1828100, 821.655029, 828.070007],\n",
    "        [819.929993, 824.400024, 1438100, 818.97998, 824.159973],\n",
    "        [816, 820.958984, 1008100, 815.48999, 819.23999],\n",
    "        [819.359985, 823, 1188100, 818.469971, 818.97998],\n",
    "        [819, 823, 1198100, 816, 820.450012],\n",
    "        [811.700012, 815.25, 1098100, 809.780029, 813.669983],\n",
    "        [809.51001, 816.659973, 1398100, 804.539978, 809.559998],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# very important. It does not work without it.\n",
    "xy = min_max_scaler(xy)\n",
    "print(xy)\n",
    "\n",
    "'''\n",
    "[[0.99999999 0.99999999 0.         1.         1.        ]\n",
    " [0.70548491 0.70439552 1.         0.71881782 0.83755791]\n",
    " [0.54412549 0.50274824 0.57608696 0.606468   0.6606331 ]\n",
    " [0.33890353 0.31368023 0.10869565 0.45989134 0.43800918]\n",
    " [0.51436    0.42582389 0.30434783 0.58504805 0.42624401]\n",
    " [0.49556179 0.42582389 0.31521739 0.48131134 0.49276137]\n",
    " [0.11436064 0.         0.20652174 0.22007776 0.18597238]\n",
    " [0.         0.07747099 0.5326087  0.         0.        ]]\n",
    "'''\n",
    "\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 4])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-5).minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "with tf.Session() as sess:\n",
    "    # Initializes global variables in the graph.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(101):\n",
    "        _, cost_val, hy_val = sess.run(\n",
    "            [train, cost, hypothesis], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd19a14-d59c-4b70-a6b4-f8e27988e38d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7fd72f-7bdf-40ef-b26d-c49396c1cd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
